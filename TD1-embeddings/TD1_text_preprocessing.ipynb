{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbo0M0vkadaR"
   },
   "source": [
    "# Text Pre-processing\n",
    "\n",
    "In this notebook, you will learn how to pre-process text data using two key techniques: **regular expressions** and **SpaCy**.\n",
    "\n",
    "## Objectives\n",
    "1. **Regular Expressions:**\n",
    "   - Understand the basics of regular expressions (regex) and their syntax.\n",
    "   - Learn how to use regex for tasks such as extracting patterns, validating formats, and cleaning text data.\n",
    "\n",
    "2. **SpaCy:**\n",
    "   - Get familiar with SpaCy, a powerful Natural Language Processing (NLP) library in Python.\n",
    "   - Discover how to perform various text pre-processing tasks with SpaCy, including:\n",
    "     - **Tokenization:** Splitting text into individual words or tokens.\n",
    "     - **Lemmatization:** Reducing words to their base or root forms.\n",
    "     - **Stop Word Removal:** Identifying and removing common words that may not carry significant meaning.\n",
    "     - **Lowercasing:** Converting all text to lowercase for consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhZ8CLGGa1xz"
   },
   "source": [
    "## Part 0 Web-Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqDhJUPMkL_y"
   },
   "source": [
    "### `requests` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zF4fuwlugwkY",
    "outputId": "c3589061-4a83-495f-81b4-f2e36f76288b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}, {'userId': 1, 'id': 2, 'title': 'qui est esse', 'body': 'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla'}, {'userId': 1, 'id': 3, 'title': 'ea molestias quasi exercitationem repellat qui ipsa sit aut', 'body': 'et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut'}, {'userId': 1, 'id': 4, 'title': 'eum et est occaecati', 'body': 'ullam et saepe reiciendis voluptatem adipisci\\nsit amet autem assumenda provident rerum culpa\\nquis hic commodi nesciunt rem tenetur doloremque ipsam iure\\nquis sunt voluptatem rerum illo velit'}, {'userId': 1, 'id': 5, 'title': 'nesciunt quas odio', 'body': 'repudiandae veniam quaerat sunt sed\\nalias aut fugiat sit autem sed est\\nvoluptatem omnis possimus esse voluptatibus quis\\nest aut tenetur dolor neque'}, {'userId': 1, 'id': 6, 'title': 'dolorem eum magni eos aperiam quia', 'body': 'ut aspernatur corporis harum nihil quis provident sequi\\nmollitia nobis aliquid molestiae\\nperspiciatis et ea nemo ab reprehenderit accusantium quas\\nvoluptate dolores velit et doloremque molestiae'}, {'userId': 1, 'id': 7, 'title': 'magnam facilis autem', 'body': 'dolore placeat quibusdam ea quo vitae\\nmagni quis enim qui quis quo nemo aut saepe\\nquidem repellat excepturi ut quia\\nsunt ut sequi eos ea sed quas'}, {'userId': 1, 'id': 8, 'title': 'dolorem dolore est ipsam', 'body': 'dignissimos aperiam dolorem qui eum\\nfacilis quibusdam animi sint suscipit qui sint possimus cum\\nquaerat magni maiores excepturi\\nipsam ut commodi dolor voluptatum modi aut vitae'}, {'userId': 1, 'id': 9, 'title': 'nesciunt iure omnis dolorem tempora et accusantium', 'body': 'consectetur animi nesciunt iure dolore\\nenim quia ad\\nveniam autem ut quam aut nobis\\net est aut quod aut provident voluptas autem voluptas'}, {'userId': 1, 'id': 10, 'title': 'optio molestias id quia eum', 'body': 'quo et expedita modi cum officia vel magni\\ndoloribus qui repudiandae\\nvero nisi sit\\nquos veniam quod sed accusamus veritatis error'}, {'userId': 2, 'id': 11, 'title': 'et ea vero quia laudantium autem', 'body': 'delectus reiciendis molestiae occaecati non minima eveniet qui voluptatibus\\naccusamus in eum beatae sit\\nvel qui neque voluptates ut commodi qui incidunt\\nut animi commodi'}, {'userId': 2, 'id': 12, 'title': 'in quibusdam tempore odit est dolorem', 'body': 'itaque id aut magnam\\npraesentium quia et ea odit et ea voluptas et\\nsapiente quia nihil amet occaecati quia id voluptatem\\nincidunt ea est distinctio odio'}, {'userId': 2, 'id': 13, 'title': 'dolorum ut in voluptas mollitia et saepe quo animi', 'body': 'aut dicta possimus sint mollitia voluptas commodi quo doloremque\\niste corrupti reiciendis voluptatem eius rerum\\nsit cumque quod eligendi laborum minima\\nperferendis recusandae assumenda consectetur porro architecto ipsum ipsam'}, {'userId': 2, 'id': 14, 'title': 'voluptatem eligendi optio', 'body': 'fuga et accusamus dolorum perferendis illo voluptas\\nnon doloremque neque facere\\nad qui dolorum molestiae beatae\\nsed aut voluptas totam sit illum'}, {'userId': 2, 'id': 15, 'title': 'eveniet quod temporibus', 'body': 'reprehenderit quos placeat\\nvelit minima officia dolores impedit repudiandae molestiae nam\\nvoluptas recusandae quis delectus\\nofficiis harum fugiat vitae'}, {'userId': 2, 'id': 16, 'title': 'sint suscipit perspiciatis velit dolorum rerum ipsa laboriosam odio', 'body': 'suscipit nam nisi quo aperiam aut\\nasperiores eos fugit maiores voluptatibus quia\\nvoluptatem quis ullam qui in alias quia est\\nconsequatur magni mollitia accusamus ea nisi voluptate dicta'}, {'userId': 2, 'id': 17, 'title': 'fugit voluptas sed molestias voluptatem provident', 'body': 'eos voluptas et aut odit natus earum\\naspernatur fuga molestiae ullam\\ndeserunt ratione qui eos\\nqui nihil ratione nemo velit ut aut id quo'}, {'userId': 2, 'id': 18, 'title': 'voluptate et itaque vero tempora molestiae', 'body': 'eveniet quo quis\\nlaborum totam consequatur non dolor\\nut et est repudiandae\\nest voluptatem vel debitis et magnam'}, {'userId': 2, 'id': 19, 'title': 'adipisci placeat illum aut reiciendis qui', 'body': 'illum quis cupiditate provident sit magnam\\nea sed aut omnis\\nveniam maiores ullam consequatur atque\\nadipisci quo iste expedita sit quos voluptas'}, {'userId': 2, 'id': 20, 'title': 'doloribus ad provident suscipit at', 'body': 'qui consequuntur ducimus possimus quisquam amet similique\\nsuscipit porro ipsam amet\\neos veritatis officiis exercitationem vel fugit aut necessitatibus totam\\nomnis rerum consequatur expedita quidem cumque explicabo'}, {'userId': 3, 'id': 21, 'title': 'asperiores ea ipsam voluptatibus modi minima quia sint', 'body': 'repellat aliquid praesentium dolorem quo\\nsed totam minus non itaque\\nnihil labore molestiae sunt dolor eveniet hic recusandae veniam\\ntempora et tenetur expedita sunt'}, {'userId': 3, 'id': 22, 'title': 'dolor sint quo a velit explicabo quia nam', 'body': 'eos qui et ipsum ipsam suscipit aut\\nsed omnis non odio\\nexpedita earum mollitia molestiae aut atque rem suscipit\\nnam impedit esse'}, {'userId': 3, 'id': 23, 'title': 'maxime id vitae nihil numquam', 'body': 'veritatis unde neque eligendi\\nquae quod architecto quo neque vitae\\nest illo sit tempora doloremque fugit quod\\net et vel beatae sequi ullam sed tenetur perspiciatis'}, {'userId': 3, 'id': 24, 'title': 'autem hic labore sunt dolores incidunt', 'body': 'enim et ex nulla\\nomnis voluptas quia qui\\nvoluptatem consequatur numquam aliquam sunt\\ntotam recusandae id dignissimos aut sed asperiores deserunt'}, {'userId': 3, 'id': 25, 'title': 'rem alias distinctio quo quis', 'body': 'ullam consequatur ut\\nomnis quis sit vel consequuntur\\nipsa eligendi ipsum molestiae et omnis error nostrum\\nmolestiae illo tempore quia et distinctio'}, {'userId': 3, 'id': 26, 'title': 'est et quae odit qui non', 'body': 'similique esse doloribus nihil accusamus\\nomnis dolorem fuga consequuntur reprehenderit fugit recusandae temporibus\\nperspiciatis cum ut laudantium\\nomnis aut molestiae vel vero'}, {'userId': 3, 'id': 27, 'title': 'quasi id et eos tenetur aut quo autem', 'body': 'eum sed dolores ipsam sint possimus debitis occaecati\\ndebitis qui qui et\\nut placeat enim earum aut odit facilis\\nconsequatur suscipit necessitatibus rerum sed inventore temporibus consequatur'}, {'userId': 3, 'id': 28, 'title': 'delectus ullam et corporis nulla voluptas sequi', 'body': 'non et quaerat ex quae ad maiores\\nmaiores recusandae totam aut blanditiis mollitia quas illo\\nut voluptatibus voluptatem\\nsimilique nostrum eum'}, {'userId': 3, 'id': 29, 'title': 'iusto eius quod necessitatibus culpa ea', 'body': 'odit magnam ut saepe sed non qui\\ntempora atque nihil\\naccusamus illum doloribus illo dolor\\neligendi repudiandae odit magni similique sed cum maiores'}, {'userId': 3, 'id': 30, 'title': 'a quo magni similique perferendis', 'body': 'alias dolor cumque\\nimpedit blanditiis non eveniet odio maxime\\nblanditiis amet eius quis tempora quia autem rem\\na provident perspiciatis quia'}, {'userId': 4, 'id': 31, 'title': 'ullam ut quidem id aut vel consequuntur', 'body': 'debitis eius sed quibusdam non quis consectetur vitae\\nimpedit ut qui consequatur sed aut in\\nquidem sit nostrum et maiores adipisci atque\\nquaerat voluptatem adipisci repudiandae'}, {'userId': 4, 'id': 32, 'title': 'doloremque illum aliquid sunt', 'body': 'deserunt eos nobis asperiores et hic\\nest debitis repellat molestiae optio\\nnihil ratione ut eos beatae quibusdam distinctio maiores\\nearum voluptates et aut adipisci ea maiores voluptas maxime'}, {'userId': 4, 'id': 33, 'title': 'qui explicabo molestiae dolorem', 'body': 'rerum ut et numquam laborum odit est sit\\nid qui sint in\\nquasi tenetur tempore aperiam et quaerat qui in\\nrerum officiis sequi cumque quod'}, {'userId': 4, 'id': 34, 'title': 'magnam ut rerum iure', 'body': 'ea velit perferendis earum ut voluptatem voluptate itaque iusto\\ntotam pariatur in\\nnemo voluptatem voluptatem autem magni tempora minima in\\nest distinctio qui assumenda accusamus dignissimos officia nesciunt nobis'}, {'userId': 4, 'id': 35, 'title': 'id nihil consequatur molestias animi provident', 'body': 'nisi error delectus possimus ut eligendi vitae\\nplaceat eos harum cupiditate facilis reprehenderit voluptatem beatae\\nmodi ducimus quo illum voluptas eligendi\\net nobis quia fugit'}, {'userId': 4, 'id': 36, 'title': 'fuga nam accusamus voluptas reiciendis itaque', 'body': 'ad mollitia et omnis minus architecto odit\\nvoluptas doloremque maxime aut non ipsa qui alias veniam\\nblanditiis culpa aut quia nihil cumque facere et occaecati\\nqui aspernatur quia eaque ut aperiam inventore'}, {'userId': 4, 'id': 37, 'title': 'provident vel ut sit ratione est', 'body': 'debitis et eaque non officia sed nesciunt pariatur vel\\nvoluptatem iste vero et ea\\nnumquam aut expedita ipsum nulla in\\nvoluptates omnis consequatur aut enim officiis in quam qui'}, {'userId': 4, 'id': 38, 'title': 'explicabo et eos deleniti nostrum ab id repellendus', 'body': 'animi esse sit aut sit nesciunt assumenda eum voluptas\\nquia voluptatibus provident quia necessitatibus ea\\nrerum repudiandae quia voluptatem delectus fugit aut id quia\\nratione optio eos iusto veniam iure'}, {'userId': 4, 'id': 39, 'title': 'eos dolorem iste accusantium est eaque quam', 'body': 'corporis rerum ducimus vel eum accusantium\\nmaxime aspernatur a porro possimus iste omnis\\nest in deleniti asperiores fuga aut\\nvoluptas sapiente vel dolore minus voluptatem incidunt ex'}, {'userId': 4, 'id': 40, 'title': 'enim quo cumque', 'body': 'ut voluptatum aliquid illo tenetur nemo sequi quo facilis\\nipsum rem optio mollitia quas\\nvoluptatem eum voluptas qui\\nunde omnis voluptatem iure quasi maxime voluptas nam'}, {'userId': 5, 'id': 41, 'title': 'non est facere', 'body': 'molestias id nostrum\\nexcepturi molestiae dolore omnis repellendus quaerat saepe\\nconsectetur iste quaerat tenetur asperiores accusamus ex ut\\nnam quidem est ducimus sunt debitis saepe'}, {'userId': 5, 'id': 42, 'title': 'commodi ullam sint et excepturi error explicabo praesentium voluptas', 'body': 'odio fugit voluptatum ducimus earum autem est incidunt voluptatem\\nodit reiciendis aliquam sunt sequi nulla dolorem\\nnon facere repellendus voluptates quia\\nratione harum vitae ut'}, {'userId': 5, 'id': 43, 'title': 'eligendi iste nostrum consequuntur adipisci praesentium sit beatae perferendis', 'body': 'similique fugit est\\nillum et dolorum harum et voluptate eaque quidem\\nexercitationem quos nam commodi possimus cum odio nihil nulla\\ndolorum exercitationem magnam ex et a et distinctio debitis'}, {'userId': 5, 'id': 44, 'title': 'optio dolor molestias sit', 'body': 'temporibus est consectetur dolore\\net libero debitis vel velit laboriosam quia\\nipsum quibusdam qui itaque fuga rem aut\\nea et iure quam sed maxime ut distinctio quae'}, {'userId': 5, 'id': 45, 'title': 'ut numquam possimus omnis eius suscipit laudantium iure', 'body': 'est natus reiciendis nihil possimus aut provident\\nex et dolor\\nrepellat pariatur est\\nnobis rerum repellendus dolorem autem'}, {'userId': 5, 'id': 46, 'title': 'aut quo modi neque nostrum ducimus', 'body': 'voluptatem quisquam iste\\nvoluptatibus natus officiis facilis dolorem\\nquis quas ipsam\\nvel et voluptatum in aliquid'}, {'userId': 5, 'id': 47, 'title': 'quibusdam cumque rem aut deserunt', 'body': 'voluptatem assumenda ut qui ut cupiditate aut impedit veniam\\noccaecati nemo illum voluptatem laudantium\\nmolestiae beatae rerum ea iure soluta nostrum\\neligendi et voluptate'}, {'userId': 5, 'id': 48, 'title': 'ut voluptatem illum ea doloribus itaque eos', 'body': 'voluptates quo voluptatem facilis iure occaecati\\nvel assumenda rerum officia et\\nillum perspiciatis ab deleniti\\nlaudantium repellat ad ut et autem reprehenderit'}, {'userId': 5, 'id': 49, 'title': 'laborum non sunt aut ut assumenda perspiciatis voluptas', 'body': 'inventore ab sint\\nnatus fugit id nulla sequi architecto nihil quaerat\\neos tenetur in in eum veritatis non\\nquibusdam officiis aspernatur cumque aut commodi aut'}, {'userId': 5, 'id': 50, 'title': 'repellendus qui recusandae incidunt voluptates tenetur qui omnis exercitationem', 'body': 'error suscipit maxime adipisci consequuntur recusandae\\nvoluptas eligendi et est et voluptates\\nquia distinctio ab amet quaerat molestiae et vitae\\nadipisci impedit sequi nesciunt quis consectetur'}, {'userId': 6, 'id': 51, 'title': 'soluta aliquam aperiam consequatur illo quis voluptas', 'body': 'sunt dolores aut doloribus\\ndolore doloribus voluptates tempora et\\ndoloremque et quo\\ncum asperiores sit consectetur dolorem'}, {'userId': 6, 'id': 52, 'title': 'qui enim et consequuntur quia animi quis voluptate quibusdam', 'body': 'iusto est quibusdam fuga quas quaerat molestias\\na enim ut sit accusamus enim\\ntemporibus iusto accusantium provident architecto\\nsoluta esse reprehenderit qui laborum'}, {'userId': 6, 'id': 53, 'title': 'ut quo aut ducimus alias', 'body': 'minima harum praesentium eum rerum illo dolore\\nquasi exercitationem rerum nam\\nporro quis neque quo\\nconsequatur minus dolor quidem veritatis sunt non explicabo similique'}, {'userId': 6, 'id': 54, 'title': 'sit asperiores ipsam eveniet odio non quia', 'body': 'totam corporis dignissimos\\nvitae dolorem ut occaecati accusamus\\nex velit deserunt\\net exercitationem vero incidunt corrupti mollitia'}, {'userId': 6, 'id': 55, 'title': 'sit vel voluptatem et non libero', 'body': 'debitis excepturi ea perferendis harum libero optio\\neos accusamus cum fuga ut sapiente repudiandae\\net ut incidunt omnis molestiae\\nnihil ut eum odit'}, {'userId': 6, 'id': 56, 'title': 'qui et at rerum necessitatibus', 'body': 'aut est omnis dolores\\nneque rerum quod ea rerum velit pariatur beatae excepturi\\net provident voluptas corrupti\\ncorporis harum reprehenderit dolores eligendi'}, {'userId': 6, 'id': 57, 'title': 'sed ab est est', 'body': 'at pariatur consequuntur earum quidem\\nquo est laudantium soluta voluptatem\\nqui ullam et est\\net cum voluptas voluptatum repellat est'}, {'userId': 6, 'id': 58, 'title': 'voluptatum itaque dolores nisi et quasi', 'body': 'veniam voluptatum quae adipisci id\\net id quia eos ad et dolorem\\naliquam quo nisi sunt eos impedit error\\nad similique veniam'}, {'userId': 6, 'id': 59, 'title': 'qui commodi dolor at maiores et quis id accusantium', 'body': 'perspiciatis et quam ea autem temporibus non voluptatibus qui\\nbeatae a earum officia nesciunt dolores suscipit voluptas et\\nanimi doloribus cum rerum quas et magni\\net hic ut ut commodi expedita sunt'}, {'userId': 6, 'id': 60, 'title': 'consequatur placeat omnis quisquam quia reprehenderit fugit veritatis facere', 'body': 'asperiores sunt ab assumenda cumque modi velit\\nqui esse omnis\\nvoluptate et fuga perferendis voluptas\\nillo ratione amet aut et omnis'}, {'userId': 7, 'id': 61, 'title': 'voluptatem doloribus consectetur est ut ducimus', 'body': 'ab nemo optio odio\\ndelectus tenetur corporis similique nobis repellendus rerum omnis facilis\\nvero blanditiis debitis in nesciunt doloribus dicta dolores\\nmagnam minus velit'}, {'userId': 7, 'id': 62, 'title': 'beatae enim quia vel', 'body': 'enim aspernatur illo distinctio quae praesentium\\nbeatae alias amet delectus qui voluptate distinctio\\nodit sint accusantium autem omnis\\nquo molestiae omnis ea eveniet optio'}, {'userId': 7, 'id': 63, 'title': 'voluptas blanditiis repellendus animi ducimus error sapiente et suscipit', 'body': 'enim adipisci aspernatur nemo\\nnumquam omnis facere dolorem dolor ex quis temporibus incidunt\\nab delectus culpa quo reprehenderit blanditiis asperiores\\naccusantium ut quam in voluptatibus voluptas ipsam dicta'}, {'userId': 7, 'id': 64, 'title': 'et fugit quas eum in in aperiam quod', 'body': 'id velit blanditiis\\neum ea voluptatem\\nmolestiae sint occaecati est eos perspiciatis\\nincidunt a error provident eaque aut aut qui'}, {'userId': 7, 'id': 65, 'title': 'consequatur id enim sunt et et', 'body': 'voluptatibus ex esse\\nsint explicabo est aliquid cumque adipisci fuga repellat labore\\nmolestiae corrupti ex saepe at asperiores et perferendis\\nnatus id esse incidunt pariatur'}, {'userId': 7, 'id': 66, 'title': 'repudiandae ea animi iusto', 'body': 'officia veritatis tenetur vero qui itaque\\nsint non ratione\\nsed et ut asperiores iusto eos molestiae nostrum\\nveritatis quibusdam et nemo iusto saepe'}, {'userId': 7, 'id': 67, 'title': 'aliquid eos sed fuga est maxime repellendus', 'body': 'reprehenderit id nostrum\\nvoluptas doloremque pariatur sint et accusantium quia quod aspernatur\\net fugiat amet\\nnon sapiente et consequatur necessitatibus molestiae'}, {'userId': 7, 'id': 68, 'title': 'odio quis facere architecto reiciendis optio', 'body': 'magnam molestiae perferendis quisquam\\nqui cum reiciendis\\nquaerat animi amet hic inventore\\nea quia deleniti quidem saepe porro velit'}, {'userId': 7, 'id': 69, 'title': 'fugiat quod pariatur odit minima', 'body': 'officiis error culpa consequatur modi asperiores et\\ndolorum assumenda voluptas et vel qui aut vel rerum\\nvoluptatum quisquam perspiciatis quia rerum consequatur totam quas\\nsequi commodi repudiandae asperiores et saepe a'}, {'userId': 7, 'id': 70, 'title': 'voluptatem laborum magni', 'body': 'sunt repellendus quae\\nest asperiores aut deleniti esse accusamus repellendus quia aut\\nquia dolorem unde\\neum tempora esse dolore'}, {'userId': 8, 'id': 71, 'title': 'et iusto veniam et illum aut fuga', 'body': 'occaecati a doloribus\\niste saepe consectetur placeat eum voluptate dolorem et\\nqui quo quia voluptas\\nrerum ut id enim velit est perferendis'}, {'userId': 8, 'id': 72, 'title': 'sint hic doloribus consequatur eos non id', 'body': 'quam occaecati qui deleniti consectetur\\nconsequatur aut facere quas exercitationem aliquam hic voluptas\\nneque id sunt ut aut accusamus\\nsunt consectetur expedita inventore velit'}, {'userId': 8, 'id': 73, 'title': 'consequuntur deleniti eos quia temporibus ab aliquid at', 'body': 'voluptatem cumque tenetur consequatur expedita ipsum nemo quia explicabo\\naut eum minima consequatur\\ntempore cumque quae est et\\net in consequuntur voluptatem voluptates aut'}, {'userId': 8, 'id': 74, 'title': 'enim unde ratione doloribus quas enim ut sit sapiente', 'body': 'odit qui et et necessitatibus sint veniam\\nmollitia amet doloremque molestiae commodi similique magnam et quam\\nblanditiis est itaque\\nquo et tenetur ratione occaecati molestiae tempora'}, {'userId': 8, 'id': 75, 'title': 'dignissimos eum dolor ut enim et delectus in', 'body': 'commodi non non omnis et voluptas sit\\nautem aut nobis magnam et sapiente voluptatem\\net laborum repellat qui delectus facilis temporibus\\nrerum amet et nemo voluptate expedita adipisci error dolorem'}, {'userId': 8, 'id': 76, 'title': 'doloremque officiis ad et non perferendis', 'body': 'ut animi facere\\ntotam iusto tempore\\nmolestiae eum aut et dolorem aperiam\\nquaerat recusandae totam odio'}, {'userId': 8, 'id': 77, 'title': 'necessitatibus quasi exercitationem odio', 'body': 'modi ut in nulla repudiandae dolorum nostrum eos\\naut consequatur omnis\\nut incidunt est omnis iste et quam\\nvoluptates sapiente aliquam asperiores nobis amet corrupti repudiandae provident'}, {'userId': 8, 'id': 78, 'title': 'quam voluptatibus rerum veritatis', 'body': 'nobis facilis odit tempore cupiditate quia\\nassumenda doloribus rerum qui ea\\nillum et qui totam\\naut veniam repellendus'}, {'userId': 8, 'id': 79, 'title': 'pariatur consequatur quia magnam autem omnis non amet', 'body': 'libero accusantium et et facere incidunt sit dolorem\\nnon excepturi qui quia sed laudantium\\nquisquam molestiae ducimus est\\nofficiis esse molestiae iste et quos'}, {'userId': 8, 'id': 80, 'title': 'labore in ex et explicabo corporis aut quas', 'body': 'ex quod dolorem ea eum iure qui provident amet\\nquia qui facere excepturi et repudiandae\\nasperiores molestias provident\\nminus incidunt vero fugit rerum sint sunt excepturi provident'}, {'userId': 9, 'id': 81, 'title': 'tempora rem veritatis voluptas quo dolores vero', 'body': 'facere qui nesciunt est voluptatum voluptatem nisi\\nsequi eligendi necessitatibus ea at rerum itaque\\nharum non ratione velit laboriosam quis consequuntur\\nex officiis minima doloremque voluptas ut aut'}, {'userId': 9, 'id': 82, 'title': 'laudantium voluptate suscipit sunt enim enim', 'body': 'ut libero sit aut totam inventore sunt\\nporro sint qui sunt molestiae\\nconsequatur cupiditate qui iste ducimus adipisci\\ndolor enim assumenda soluta laboriosam amet iste delectus hic'}, {'userId': 9, 'id': 83, 'title': 'odit et voluptates doloribus alias odio et', 'body': 'est molestiae facilis quis tempora numquam nihil qui\\nvoluptate sapiente consequatur est qui\\nnecessitatibus autem aut ipsa aperiam modi dolore numquam\\nreprehenderit eius rem quibusdam'}, {'userId': 9, 'id': 84, 'title': 'optio ipsam molestias necessitatibus occaecati facilis veritatis dolores aut', 'body': 'sint molestiae magni a et quos\\neaque et quasi\\nut rerum debitis similique veniam\\nrecusandae dignissimos dolor incidunt consequatur odio'}, {'userId': 9, 'id': 85, 'title': 'dolore veritatis porro provident adipisci blanditiis et sunt', 'body': 'similique sed nisi voluptas iusto omnis\\nmollitia et quo\\nassumenda suscipit officia magnam sint sed tempora\\nenim provident pariatur praesentium atque animi amet ratione'}, {'userId': 9, 'id': 86, 'title': 'placeat quia et porro iste', 'body': 'quasi excepturi consequatur iste autem temporibus sed molestiae beatae\\net quaerat et esse ut\\nvoluptatem occaecati et vel explicabo autem\\nasperiores pariatur deserunt optio'}, {'userId': 9, 'id': 87, 'title': 'nostrum quis quasi placeat', 'body': 'eos et molestiae\\nnesciunt ut a\\ndolores perspiciatis repellendus repellat aliquid\\nmagnam sint rem ipsum est'}, {'userId': 9, 'id': 88, 'title': 'sapiente omnis fugit eos', 'body': 'consequatur omnis est praesentium\\nducimus non iste\\nneque hic deserunt\\nvoluptatibus veniam cum et rerum sed'}, {'userId': 9, 'id': 89, 'title': 'sint soluta et vel magnam aut ut sed qui', 'body': 'repellat aut aperiam totam temporibus autem et\\narchitecto magnam ut\\nconsequatur qui cupiditate rerum quia soluta dignissimos nihil iure\\ntempore quas est'}, {'userId': 9, 'id': 90, 'title': 'ad iusto omnis odit dolor voluptatibus', 'body': 'minus omnis soluta quia\\nqui sed adipisci voluptates illum ipsam voluptatem\\neligendi officia ut in\\neos soluta similique molestias praesentium blanditiis'}, {'userId': 10, 'id': 91, 'title': 'aut amet sed', 'body': 'libero voluptate eveniet aperiam sed\\nsunt placeat suscipit molestias\\nsimilique fugit nam natus\\nexpedita consequatur consequatur dolores quia eos et placeat'}, {'userId': 10, 'id': 92, 'title': 'ratione ex tenetur perferendis', 'body': 'aut et excepturi dicta laudantium sint rerum nihil\\nlaudantium et at\\na neque minima officia et similique libero et\\ncommodi voluptate qui'}, {'userId': 10, 'id': 93, 'title': 'beatae soluta recusandae', 'body': 'dolorem quibusdam ducimus consequuntur dicta aut quo laboriosam\\nvoluptatem quis enim recusandae ut sed sunt\\nnostrum est odit totam\\nsit error sed sunt eveniet provident qui nulla'}, {'userId': 10, 'id': 94, 'title': 'qui qui voluptates illo iste minima', 'body': 'aspernatur expedita soluta quo ab ut similique\\nexpedita dolores amet\\nsed temporibus distinctio magnam saepe deleniti\\nomnis facilis nam ipsum natus sint similique omnis'}, {'userId': 10, 'id': 95, 'title': 'id minus libero illum nam ad officiis', 'body': 'earum voluptatem facere provident blanditiis velit laboriosam\\npariatur accusamus odio saepe\\ncumque dolor qui a dicta ab doloribus consequatur omnis\\ncorporis cupiditate eaque assumenda ad nesciunt'}, {'userId': 10, 'id': 96, 'title': 'quaerat velit veniam amet cupiditate aut numquam ut sequi', 'body': 'in non odio excepturi sint eum\\nlabore voluptates vitae quia qui et\\ninventore itaque rerum\\nveniam non exercitationem delectus aut'}, {'userId': 10, 'id': 97, 'title': 'quas fugiat ut perspiciatis vero provident', 'body': 'eum non blanditiis soluta porro quibusdam voluptas\\nvel voluptatem qui placeat dolores qui velit aut\\nvel inventore aut cumque culpa explicabo aliquid at\\nperspiciatis est et voluptatem dignissimos dolor itaque sit nam'}, {'userId': 10, 'id': 98, 'title': 'laboriosam dolor voluptates', 'body': 'doloremque ex facilis sit sint culpa\\nsoluta assumenda eligendi non ut eius\\nsequi ducimus vel quasi\\nveritatis est dolores'}, {'userId': 10, 'id': 99, 'title': 'temporibus sit alias delectus eligendi possimus magni', 'body': 'quo deleniti praesentium dicta non quod\\naut est molestias\\nmolestias et officia quis nihil\\nitaque dolorem quia'}, {'userId': 10, 'id': 100, 'title': 'at nam consequatur ea labore ea harum', 'body': 'cupiditate quo est a modi nesciunt soluta\\nipsa voluptas error itaque dicta in\\nautem qui minus magnam et distinctio eum\\naccusamus ratione error aut'}]\n",
      "<class 'list'>\n",
      "Post ID: 1, Title: sunt aut facere repellat provident occaecati excepturi optio reprehenderit\n",
      "Post ID: 2, Title: qui est esse\n",
      "Post ID: 3, Title: ea molestias quasi exercitationem repellat qui ipsa sit aut\n",
      "Post ID: 4, Title: eum et est occaecati\n",
      "Post ID: 5, Title: nesciunt quas odio\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# example of parsing\n",
    "# JSONPlaceholder API URL to get a list of posts\n",
    "URL = 'https://jsonplaceholder.typicode.com/posts'\n",
    "\n",
    "# Make a GET request\n",
    "response = requests.get(URL)\n",
    "# if authentification is needed:\n",
    "# data = {'username': 'user', 'password': 'pass'}\n",
    "# response = requests.post(URL+'/login', data=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "posts=None\n",
    "if response.status_code == 200:\n",
    "    posts = response.json()  # Parse the JSON response\n",
    "\n",
    "else:\n",
    "    print('Error:', response.status_code)# same as if response.status_code == 404\n",
    "print(posts)\n",
    "print(type(posts))#==<class 'list'> of dicts of the following type:\n",
    "# {'userId': 4, 'id': 32, 'title': 'doloremque illum aliquid sunt', 'body': 'value'}\n",
    "if posts:\n",
    "  for post in posts[:5]:  # Print the first 5 posts\n",
    "      print(f\"Post ID: {post['id']}, Title: {post['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zjlp92Hg6n0"
   },
   "source": [
    "**Session Management**\n",
    "\n",
    "`requests` library supports session management, allowing you to maintain state (like cookies) across multiple requests.\n",
    "This is useful for logging in to websites or interacting with web applications that require authentication.\n",
    "Example:\n",
    "```\n",
    "session = requests.Session()\n",
    "#create a session object\n",
    "session = requests.Session()\n",
    "\n",
    "# set default headers (optional)\n",
    "session.headers.update({'User-Agent': 'my-app'})\n",
    "\n",
    "# make the first request\n",
    "response1 = session.get('https://jsonplaceholder.typicode.com/posts/1')\n",
    "print('First Post Title:', response1.json()['title'])\n",
    "\n",
    "# make another request using the same session\n",
    "response2 = session.get('https://jsonplaceholder.typicode.com/posts/2')\n",
    "print('Second Post Title:', response2.json()['title'])\n",
    "\n",
    "#close the session when done\n",
    "session.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwGxFuCikQPn"
   },
   "source": [
    "### `beautifulsoup4` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xHesNHyqiLib"
   },
   "outputs": [],
   "source": [
    "# Save the URL of the webpage we want to scrape to a variable\n",
    "url = 'https://docs.python.org/3/library/random.html#module-random'\n",
    "# Send a get request and assign the response to a variable\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "dfw2cB1rlnyq",
    "outputId": "207aa6b0-30e8-4b6e-ea73-1be33d543509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>bs4.BeautifulSoup</b><br/>def __call__(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/bs4/__init__.py</a>A data structure representing a parsed HTML or XML document.\n",
       "\n",
       "Most of the methods you&#x27;ll call on a BeautifulSoup object are inherited from\n",
       "PageElement or Tag.\n",
       "\n",
       "Internally, this class defines the basic interface called by the\n",
       "tree builders when converting an HTML/XML document into a data\n",
       "structure. The interface abstracts away the differences between\n",
       "parsers. To write a new tree builder, you&#x27;ll need to understand\n",
       "these methods as a whole.\n",
       "\n",
       "These methods will be called by the BeautifulSoup constructor:\n",
       "  * reset()\n",
       "  * feed(markup)\n",
       "\n",
       "The tree builder may call these methods from its feed() implementation:\n",
       "  * handle_starttag(name, attrs) # See note about return value\n",
       "  * handle_endtag(name)\n",
       "  * handle_data(data) # Appends to the current data node\n",
       "  * endData(containerClass) # Ends the current data node\n",
       "\n",
       "No matter how complicated the underlying parser is, you should be\n",
       "able to build a tree using &#x27;start tag&#x27; events, &#x27;end tag&#x27; events,\n",
       "&#x27;data&#x27; events, and &quot;done with data&quot; events.\n",
       "\n",
       "If you encounter an empty-element tag (aka a self-closing tag,\n",
       "like HTML&#x27;s &lt;br&gt; tag), call handle_starttag and then\n",
       "handle_endtag.</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 76);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Turn the undecoded content into a Beautiful Soup object and assign it to a variable\n",
    "soup = BeautifulSoup(response.content)\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C_Pk6dsGmvlN"
   },
   "outputs": [],
   "source": [
    "# You can print the prettified version of the soup object for better readability\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1XGmbtLltOZ",
    "outputId": "78497499-915b-468d-98f7-52cd7a826a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: random — Generate pseudo-random numbers — Python 3.13.0 documentation\n",
      "\n",
      "Function Definitions:\n",
      "\n",
      "\n",
      "random.seed(a=None, version=2)¶\n",
      "Initialize the random number generator.\n",
      "If a is omitted or None, the current system time is used.  If\n",
      "randomness sources are provided by the operating system, they are used\n",
      "instead of the system time (see the os.urandom() function for details\n",
      "on availability).\n",
      "If a is an int, it is used directly.\n",
      "With version 2 (the default), a str, bytes, or bytearray\n",
      "object gets converted to an int and all of its bits are used.\n",
      "With version 1 (provided for reproducing random sequences from older versions\n",
      "of Python), the algorithm for str and bytes generates a\n",
      "narrower range of seeds.\n",
      "\n",
      "Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed.\n",
      "\n",
      "\n",
      "Changed in version 3.11: The seed must be one of the following types:\n",
      "None, int, float, str,\n",
      "bytes, or bytearray.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random.getstate()¶\n",
      "Return an object capturing the current internal state of the generator.  This\n",
      "object can be passed to setstate() to restore the state.\n",
      "\n",
      "\n",
      "\n",
      "random.setstate(state)¶\n",
      "state should have been obtained from a previous call to getstate(), and\n",
      "setstate() restores the internal state of the generator to what it was at\n",
      "the time getstate() was called.\n",
      "\n",
      "\n",
      "Links on the Page:\n",
      "Text: None, URL: https://www.python.org/\n",
      "Text: Table of Contents, URL: ../contents.html\n",
      "Text: None, URL: #\n"
     ]
    }
   ],
   "source": [
    "# 1. Extracting the Title of the Page\n",
    "title = soup.title.string\n",
    "print('Page Title:', title)\n",
    "\n",
    "# 2. Finding Specific Elements\n",
    "# For example, let's find all function definitions in the random module\n",
    "function_definitions = soup.find_all('dl')\n",
    "\n",
    "# 3. Printing the Function Definitions\n",
    "print('\\nFunction Definitions:')\n",
    "for func in function_definitions[:3]:\n",
    "    print(func.get_text())  # Print the text of each function definition\n",
    "\n",
    "# 4. Extracting Links\n",
    "# Find all links on the page\n",
    "links = soup.find_all('a')\n",
    "print('\\nLinks on the Page:')\n",
    "for link in links[:3]:\n",
    "    href = link.get('href')  # Get the href attribute\n",
    "    text = link.string  # Get the link text\n",
    "    print(f'Text: {text}, URL: {href}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlev3BhSnMPi",
    "outputId": "e80785bd-07fd-4334-f4e1-6169073635ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptions of Functions:\n",
      "\n",
      "random.seed(a=None, version=2)¶: Initialize the random number generator.\n",
      "If a is omitted or None, the current system time is used.  If\n",
      "randomness sources are provided by the operating system, they are used\n",
      "instead of the system time (see the os.urandom() function for details\n",
      "on availability).\n",
      "If a is an int, it is used directly.\n",
      "With version 2 (the default), a str, bytes, or bytearray\n",
      "object gets converted to an int and all of its bits are used.\n",
      "With version 1 (provided for reproducing random sequences from older versions\n",
      "of Python), the algorithm for str and bytes generates a\n",
      "narrower range of seeds.\n",
      "\n",
      "Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed.\n",
      "\n",
      "\n",
      "Changed in version 3.11: The seed must be one of the following types:\n",
      "None, int, float, str,\n",
      "bytes, or bytearray.\n",
      "\n",
      "\n",
      "\n",
      "random.getstate()¶: Return an object capturing the current internal state of the generator.  This\n",
      "object can be passed to setstate() to restore the state.\n",
      "\n",
      "\n",
      "random.setstate(state)¶: state should have been obtained from a previous call to getstate(), and\n",
      "setstate() restores the internal state of the generator to what it was at\n",
      "the time getstate() was called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Extracting Descriptions\n",
    "# Find all descriptions (the first <dt> element followed by <dd>)\n",
    "# <dt>=definition term. <dd>=definition description\n",
    "print('\\nDescriptions of Functions:')\n",
    "for func in function_definitions[:3]:\n",
    "    dt_tags = func.find_all('dt')\n",
    "    dd_tags = func.find_all('dd')\n",
    "    for dt, dd in zip(dt_tags, dd_tags):\n",
    "        print(f'{dt.get_text()}: {dd.get_text()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1dxbk5CoAah"
   },
   "source": [
    "## Part 1: Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srfNyI6RuOwj"
   },
   "source": [
    "\n",
    "Regular expressions are sequences of characters that define search patterns, primarily used for string matching and manipulation. They enable powerful text processing by allowing users to define rules for finding, replacing, or extracting specific parts of a text. Commonly used for tasks like validating input (e.g., email addresses), searching for specific patterns (e.g., dates), or extracting substrings, regular expressions operate based on a series of predefined symbols and syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5Vei7RrujLy"
   },
   "source": [
    "The `re` module has several key functions:\n",
    "\n",
    "- `re.findall` (returns all matches as a list),\n",
    "- `re.match` (compares the pattern with the string from the beginning),\n",
    "- `re.search` (searches the entire string for a match with the pattern),\n",
    "- `re.sub` (replaces matches in the string with something else),\n",
    "- `re.split` (splits the string based on matches with the pattern).\n",
    "\n",
    "A **pattern** is the regular expression itself. It describes, using a special language, what we want to find in the string. It will be clearer with examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oV3C6WJ1uOe-"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"It is only with the heart that one can see rightly; what is essential is invisible to the eye.\n",
    "\n",
    "The little prince, who was very curious, traveled from planet to planet, meeting different characters. He learned that true beauty comes from the heart, and the most important things are often simple and pure.\n",
    "\n",
    "One day, he met a fox who told him, “You become responsible, forever, for what you have tamed. You are responsible for your rose.”\n",
    "\n",
    "As he continued his journey, he realized that friendship and love are what make life truly worthwhile.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTrZndU2wEwp"
   },
   "source": [
    "The simplest pattern is the substring we want to find. For example, if we want to find all occurrences of the uppercase letters \"I,\" then the pattern will simply be \"I.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EH2aDlvqwJpb",
    "outputId": "38648085-fa2d-4a7f-b6ac-bc589ec52609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I'], ['Y', 'Y'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('I', text), re.findall('Y', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMMfIXSkwWpn",
    "outputId": "cdb6122b-98b8-4439-e092-8514fc231c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('y', 'YYY') # register makes sense!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "GgPxafFBwsk4",
    "outputId": "ffd41819-487e-4a1c-b665-ae9c44dc9439"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'aaa'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('O', 'a', 'OOO')# substitute all O with a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4Z1fm_yxeHx"
   },
   "source": [
    "You can also use ranges to avoid listing all the characters, such as all letters or all digits.\n",
    "\n",
    "### Common Ranges:\n",
    "\n",
    "- `[a-z]` - all lowercase English letters\n",
    "- `[A-Z]` - all uppercase English letters\n",
    "- `[0-9]` - all digits\n",
    "- `[A-z]` - it is better to avoid using this range because, although it won't cause errors, it will include many unnecessary characters. This is because ranges are considered based on the Unicode table (https://unicode-table.com/en/), and there are other characters between English letters.\n",
    "- `[a-zA-Z]`- all English letters\n",
    "- `[a-zàâçéèêëîïôùûü]` - toutes les lettres minuscules françaises\n",
    "- `[A-ZÀÂÇÉÈÊËÎÏÔÙÛÜ]` - toutes les lettres majuscules françaises\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "2naYg4v2wxsA",
    "outputId": "18d19a49-d541-4545-eb3b-64b00697552f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'          ;        .\\n\\n  ,    ,     ,   .         ,          .\\n\\n ,       , “  , ,     .      .”\\n\\n    ,            .\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[a-zA-Z]\", '', text)# remove all letters from our text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49luXk0WzPeO"
   },
   "source": [
    "The symbol `^` inside brackets means negation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfvuCAvEzaQN",
    "outputId": "5a8b9749-f954-41d5-9775-e2419a652053"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'c',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'i',\n",
       " 'g',\n",
       " 'h',\n",
       " 't',\n",
       " 'l',\n",
       " 'y',\n",
       " ';',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'v',\n",
       " 'i',\n",
       " 's',\n",
       " 'i',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'y',\n",
       " 'e',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'i',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'y',\n",
       " ' ',\n",
       " 'c',\n",
       " 'u',\n",
       " 'r',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'n',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'n',\n",
       " 'e',\n",
       " 't',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 'e',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " '.',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'u',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 'y',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'r',\n",
       " 'e',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " 'y',\n",
       " ',',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'x',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'h',\n",
       " 'i',\n",
       " 'm',\n",
       " ',',\n",
       " ' ',\n",
       " '“',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ',',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " ',',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 'd',\n",
       " '.',\n",
       " ' ',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " ' ',\n",
       " 'r',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " '.',\n",
       " '”',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'A',\n",
       " 's',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'u',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'j',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " 'n',\n",
       " 'e',\n",
       " 'y',\n",
       " ',',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i',\n",
       " 'z',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 'd',\n",
       " 's',\n",
       " 'h',\n",
       " 'i',\n",
       " 'p',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'k',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'f',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'u',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[^D-Z]', text)# matches everything besides [D-Z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpDcwhq7ztjU"
   },
   "source": [
    "There are abstract operators that can specify even more options.\n",
    "\n",
    "### The main operators are:\n",
    "\n",
    "- `\\w \\W` - any letter or digit and any character that is not a letter or digit\n",
    "- `\\d \\D` - any digit and any character that is not a digit\n",
    "- `.` - any character except for a newline\n",
    "- `\\s` - whitespace character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "oXnuI1FFzfbw",
    "outputId": "07d2f6cf-9131-4d2e-8026-3a481b6cb57d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'          ;        .\\n\\n  ,    ,     ,   .         ,          .\\n\\n ,       , “  , ,     .      .”\\n\\n    ,            .\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only spaces and punctuation will remain\n",
    "re.sub('\\w', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "OXIUEoN2z6jW",
    "outputId": "40f63996-3e7f-419b-a993-2c194c334b69"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ItisonlywiththeheartthatonecanseerightlywhatisessentialisinvisibletotheeyeThelittleprincewhowasverycurioustraveledfromplanettoplanetmeetingdifferentcharactersHelearnedthattruebeautycomesfromtheheartandthemostimportantthingsareoftensimpleandpureOnedayhemetafoxwhotoldhimYoubecomeresponsibleforeverforwhatyouhavetamedYouareresponsibleforyourroseAshecontinuedhisjourneyherealizedthatfriendshipandlovearewhatmakelifetrulyworthwhile'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only letters will remain\n",
    "re.sub('\\W', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgqJNmSK0AJ6",
    "outputId": "1b888992-48bd-48c1-b837-0d1e3d323bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\d - no digits in the string, so it's empty\n",
    "re.findall('\\d', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "SPwZUY9M0BQy",
    "outputId": "71498552-6108-4a44-925f-4d4eea96e5f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\D - matches any non-digit, i.e., the entire string\n",
    "re.sub('\\D', '_', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OkYNq6F0HhN",
    "outputId": "1e10be84-aac7-46b1-d482-f64dffe3cd1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'only',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'one',\n",
       " 'can',\n",
       " 'see',\n",
       " 'rightly;',\n",
       " 'what',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'is',\n",
       " 'invisible',\n",
       " 'to',\n",
       " 'the',\n",
       " 'eye.',\n",
       " '',\n",
       " 'The',\n",
       " 'little',\n",
       " 'prince,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'very',\n",
       " 'curious,',\n",
       " 'traveled',\n",
       " 'from',\n",
       " 'planet',\n",
       " 'to',\n",
       " 'planet,',\n",
       " 'meeting',\n",
       " 'different',\n",
       " 'characters.',\n",
       " 'He',\n",
       " 'learned',\n",
       " 'that',\n",
       " 'true',\n",
       " 'beauty',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'the',\n",
       " 'heart,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'things',\n",
       " 'are',\n",
       " 'often',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'pure.',\n",
       " '',\n",
       " 'One',\n",
       " 'day,',\n",
       " 'he',\n",
       " 'met',\n",
       " 'a',\n",
       " 'fox',\n",
       " 'who',\n",
       " 'told',\n",
       " 'him,',\n",
       " '“You',\n",
       " 'become',\n",
       " 'responsible,',\n",
       " 'forever,',\n",
       " 'for',\n",
       " 'what',\n",
       " 'you',\n",
       " 'have',\n",
       " 'tamed.',\n",
       " 'You',\n",
       " 'are',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'your',\n",
       " 'rose.”',\n",
       " '',\n",
       " 'As',\n",
       " 'he',\n",
       " 'continued',\n",
       " 'his',\n",
       " 'journey,',\n",
       " 'he',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'friendship',\n",
       " 'and',\n",
       " 'love',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'life',\n",
       " 'truly',\n",
       " 'worthwhile.',\n",
       " '']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\s - this way you can create a simple tokenizer\n",
    "re.split(\"\\s\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nLYHDXD0lU8"
   },
   "source": [
    "To repeat the same character, you can place a `+` after it (indicating 1 or more repetitions) or a `*` (indicating 0 or more repetitions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bE4g6Q410RsF",
    "outputId": "596d3811-57ae-48a2-d2b4-7ac5007a48a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'only',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'one',\n",
       " 'can',\n",
       " 'see',\n",
       " 'rightly',\n",
       " 'what',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'is',\n",
       " 'invisible',\n",
       " 'to',\n",
       " 'the',\n",
       " 'eye',\n",
       " 'The',\n",
       " 'little',\n",
       " 'prince',\n",
       " 'who',\n",
       " 'was',\n",
       " 'very',\n",
       " 'curious',\n",
       " 'traveled',\n",
       " 'from',\n",
       " 'planet',\n",
       " 'to',\n",
       " 'planet',\n",
       " 'meeting',\n",
       " 'different',\n",
       " 'characters',\n",
       " 'He',\n",
       " 'learned',\n",
       " 'that',\n",
       " 'true',\n",
       " 'beauty',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'things',\n",
       " 'are',\n",
       " 'often',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'pure',\n",
       " 'One',\n",
       " 'day',\n",
       " 'he',\n",
       " 'met',\n",
       " 'a',\n",
       " 'fox',\n",
       " 'who',\n",
       " 'told',\n",
       " 'him',\n",
       " 'You',\n",
       " 'become',\n",
       " 'responsible',\n",
       " 'forever',\n",
       " 'for',\n",
       " 'what',\n",
       " 'you',\n",
       " 'have',\n",
       " 'tamed',\n",
       " 'You',\n",
       " 'are',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'your',\n",
       " 'rose',\n",
       " 'As',\n",
       " 'he',\n",
       " 'continued',\n",
       " 'his',\n",
       " 'journey',\n",
       " 'he',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'friendship',\n",
       " 'and',\n",
       " 'love',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'life',\n",
       " 'truly',\n",
       " 'worthwhile']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+', text)#find all sequences: words and digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK4jKf5h1io7"
   },
   "source": [
    "If the character is optional, you can place a question mark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_BrxuMh1KZI",
    "outputId": "0111b5d6-de37-4fec-cc7d-a6d6741d2cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince,',\n",
       " 'curious,',\n",
       " 'planet,',\n",
       " 'heart,',\n",
       " 'day,',\n",
       " 'him,',\n",
       " 'responsible,',\n",
       " 'forever,',\n",
       " 'journey,']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A comma at the end is required\n",
    "re.findall('\\w+,', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjeJ2Fbt1pmt",
    "outputId": "bca5b37b-5588-46c7-f676-7948d1159017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'only',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'one',\n",
       " 'can',\n",
       " 'see',\n",
       " 'rightly',\n",
       " 'what',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'is',\n",
       " 'invisible',\n",
       " 'to',\n",
       " 'the',\n",
       " 'eye',\n",
       " 'The',\n",
       " 'little',\n",
       " 'prince,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'very',\n",
       " 'curious,',\n",
       " 'traveled',\n",
       " 'from',\n",
       " 'planet',\n",
       " 'to',\n",
       " 'planet,',\n",
       " 'meeting',\n",
       " 'different',\n",
       " 'characters',\n",
       " 'He',\n",
       " 'learned',\n",
       " 'that',\n",
       " 'true',\n",
       " 'beauty',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'the',\n",
       " 'heart,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'things',\n",
       " 'are',\n",
       " 'often',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'pure',\n",
       " 'One',\n",
       " 'day,',\n",
       " 'he',\n",
       " 'met',\n",
       " 'a',\n",
       " 'fox',\n",
       " 'who',\n",
       " 'told',\n",
       " 'him,',\n",
       " 'You',\n",
       " 'become',\n",
       " 'responsible,',\n",
       " 'forever,',\n",
       " 'for',\n",
       " 'what',\n",
       " 'you',\n",
       " 'have',\n",
       " 'tamed',\n",
       " 'You',\n",
       " 'are',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'your',\n",
       " 'rose',\n",
       " 'As',\n",
       " 'he',\n",
       " 'continued',\n",
       " 'his',\n",
       " 'journey,',\n",
       " 'he',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'friendship',\n",
       " 'and',\n",
       " 'love',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'life',\n",
       " 'truly',\n",
       " 'worthwhile']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A comma is optional\n",
    "re.findall('\\w+,?', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "aUsmmFAZ28u5",
    "outputId": "b65b47a0-e07f-4564-e5ef-5c9e20d1c133"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search('\\s(.+?)\\s', text)  # with .search, you can extract what is captured in parentheses like this\n",
    "m.group(1)#the first word after the space in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBCYNREZ9XI8"
   },
   "source": [
    "Here’s a breakdown of the basic components used in regular expressions (regex):\n",
    "\n",
    "1. **Literal Characters**  \n",
    "   These are the exact characters you want to search for.  \n",
    "   **Example:** The pattern `cat` will match the string \"cat\" exactly.\n",
    "\n",
    "2. **Metacharacters**  \n",
    "   These characters have special meanings in regex patterns:  \n",
    "   - `.`: Matches any single character (except newline).  \n",
    "     **Example:** `c.t` matches \"cat\", \"cut\", \"cot\".  \n",
    "   - `^`: Matches the start of a string.  \n",
    "     **Example:** `^a` matches \"apple\", but not \"banana\".  \n",
    "   - `$`: Matches the end of a string.  \n",
    "     **Example:** `e$` matches \"apple\", but not \"ape\".  \n",
    "   - `*`: Matches 0 or more occurrences of the preceding element.  \n",
    "     **Example:** `a*` matches \"\", \"a\", \"aa\", \"aaa\", etc.  \n",
    "   - `+`: Matches 1 or more occurrences of the preceding element.  \n",
    "     **Example:** `a+` matches \"a\", \"aa\", \"aaa\", but not \"\".  \n",
    "   - `?`: Matches 0 or 1 occurrence of the preceding element.  \n",
    "     **Example:** `a?` matches \"\" or \"a\".  \n",
    "   - `\\`: Escapes a special character, so it can be matched as a literal.  \n",
    "     **Example:** `\\.` matches a period (.) rather than any character.\n",
    "\n",
    "3. **Character Classes**  \n",
    "   These define sets of characters you want to match:  \n",
    "   - `[abc]`: Matches any single character that is a, b, or c.  \n",
    "     **Example:** `b[aeiou]t` matches \"bat\", \"bet\", \"bit\", \"bot\", \"but\".  \n",
    "   - `[^abc]`: Matches any character except a, b, or c.  \n",
    "     **Example:** `[^0-9]` matches any non-digit character.  \n",
    "   - `[a-z]`: Matches any lowercase letter from a to z.  \n",
    "     **Example:** `[a-z]` matches any single lowercase letter.  \n",
    "   - `[A-Z]`: Matches any uppercase letter from A to Z.  \n",
    "     **Example:** `[A-Z]` matches any single uppercase letter.  \n",
    "   - `[0-9]`: Matches any digit from 0 to 9.  \n",
    "     **Example:** `[0-9]` matches any single digit.\n",
    "\n",
    "4. **Quantifiers**  \n",
    "   These specify how many times a preceding character or group should occur:  \n",
    "   - `{n}`: Exactly n occurrences.  \n",
    "     **Example:** `a{3}` matches \"aaa\", but not \"aa\".  \n",
    "   - `{n,}`: At least n occurrences.  \n",
    "     **Example:** `a{2,}` matches \"aa\", \"aaa\", \"aaaa\", etc.  \n",
    "   - `{n,m}`: Between n and m occurrences.  \n",
    "     **Example:** `a{2,4}` matches \"aa\", \"aaa\", \"aaaa\".\n",
    "\n",
    "5. **Anchors**  \n",
    "   These match specific positions in the text:  \n",
    "   - `^`: Start of a string.  \n",
    "     **Example:** `^Hello` matches \"Hello world\", but not \"Hi, Hello\".  \n",
    "   - `$`: End of a string.  \n",
    "     **Example:** `world$` matches \"Hello world\", but not \"world, hello\".\n",
    "\n",
    "6. **Groups and Capturing**  \n",
    "   - `(...)`: Groups multiple tokens together. Captures the matched text inside parentheses.  \n",
    "     **Example:** `(abc)+` matches \"abc\", \"abcabc\", etc.  \n",
    "   - Non-capturing group `(?:...)`: Groups tokens without capturing.  \n",
    "     **Example:** `(?:abc)+` matches \"abc\", \"abcabc\", but won’t capture it.\n",
    "\n",
    "7. **Alternation**  \n",
    "   - `|`: Represents a logical OR between patterns.  \n",
    "     **Example:** `cat|dog` matches either \"cat\" or \"dog\".\n",
    "\n",
    "8. **Escaped Characters**  \n",
    "   - `\\d`: Matches any digit ([0-9]).  \n",
    "     **Example:** `\\d` matches \"1\", \"2\", \"3\", etc.  \n",
    "   - `\\D`: Matches any non-digit.  \n",
    "     **Example:** `\\D` matches \"a\", \"b\", \"#\", etc.  \n",
    "   - `\\w`: Matches any word character (letters, digits, underscore).  \n",
    "     **Example:** `\\w` matches \"a\", \"1\", \"_\", etc.  \n",
    "   - `\\W`: Matches any non-word character.  \n",
    "     **Example:** `\\W` matches \"!\", \"@\", etc.  \n",
    "   - `\\s`: Matches any whitespace character (spaces, tabs, newlines).  \n",
    "     **Example:** `\\s` matches a space or tab.  \n",
    "   - `\\S`: Matches any non-whitespace character.  \n",
    "     **Example:** `\\S` matches \"a\", \"1\", etc.\n",
    "\n",
    "### Example Summary  \n",
    "**Pattern:** `^a.*z$`  \n",
    "**Explanation:**  \n",
    "- `^`: Start of the string.  \n",
    "- `a`: The letter \"a\".  \n",
    "- `.*`: Any characters (0 or more).  \n",
    "- `z`: The letter \"z\".  \n",
    "- `$`: End of the string.  \n",
    "\n",
    "**Matches:** Strings that start with \"a\" and end with \"z\", like \"abcz\", \"amaz\", etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CE9c4tNw61xG"
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Define a regular expression pattern to match valid email addresses. Use the `re.findall()`.\n",
    "The output should contain all email addresses in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuhVl2pr7fxx",
    "outputId": "48e69f09-2bd2-4ceb-e446-6fa17ab991e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Email Extraction Example\n",
      "\n",
      "Contact us at: john.doe@example.com\n",
      "Support: jane.smith@website.org\n",
      "Invalid email: invalid-email@\n",
      "Info: info@company.com\n",
      "Phone: +1-800-555-0199\n",
      "\n",
      "\n",
      "\n",
      "Valid Email Addresses:\n",
      "john.doe@example.com\n",
      "jane.smith@website.org\n",
      "info@company.com\n"
     ]
    }
   ],
   "source": [
    "html_content = \"\"\"\n",
    "<html>\n",
    "<head><title>Email Extraction Example</title></head>\n",
    "<body>\n",
    "    <p>Contact us at: john.doe@example.com</p>\n",
    "    <p>Support: jane.smith@website.org</p>\n",
    "    <p>Invalid email: invalid-email@</p>\n",
    "    <p>Info: info@company.com</p>\n",
    "    <p>Phone: +1-800-555-0199</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "# Find all matching email addresses in the extracted text\n",
    "email_matches = re.findall(email_pattern, text)\n",
    "\n",
    "# Output the valid email addresses\n",
    "print(\"Valid Email Addresses:\")\n",
    "for email in email_matches:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OapnQ2Ioo3S1"
   },
   "source": [
    "##Part 2: SpaCy Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ts02W4jP8JXZ"
   },
   "outputs": [],
   "source": [
    "# !pip install spacy==3.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "al94tlxA8LMT"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcMbRHAq8ikT",
    "outputId": "c3afb081-b6d7-40b3-d19d-783eb6d45f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (71.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6i7_CZi6LB2J"
   },
   "source": [
    "**In case of error executing cell below**  \n",
    "\n",
    "Select (top menu item) Runtime->Restart Runtime or **_Ctrl+M_+.**  \n",
    "Then: execute that cell _below_ (upper ones not needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJcyTIiOKTqS",
    "outputId": "8a0a78f0-d2f7-4b6f-feb1-6b631ff945a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7a33953b1810>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy # in case of restarting\n",
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dj48eDIhURv1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8KrYwKjALXs"
   },
   "source": [
    "### Text Processing with Pretrained Pipelines\n",
    "\n",
    "To process text, you first need to load a pretrained pipeline — a language model of the `Language` class, which includes a vocabulary, language data (rules used for tokenization, lemmatization, lexical attribute extraction, etc.), and the model's training results (weights).\n",
    "\n",
    "## Language Models\n",
    "\n",
    "Language models for the same language differ in the size of the vocabulary and the accuracy of components (pipes).\n",
    "\n",
    "### Components (Pipes):\n",
    "- `transformer`\n",
    "- `tagger`\n",
    "- `parser`\n",
    "- `ner`\n",
    "- `attribute_ruler`\n",
    "- `lemmatizer`\n",
    "- `senter`\n",
    "- `tok2vec`\n",
    "- Trainable pipes (non-default)\n",
    "\n",
    "## Viewing Components and Analysis\n",
    "\n",
    "You can view the list of available components and analyze the results of their operation using the following command:\n",
    "\n",
    "```python\n",
    "nlp.analyze_pipes(pretty=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gJSJ618iZfjJ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GlU0bYU2p0n",
    "outputId": "4d7aecd7-1a71-421c-a03d-8bb54b48a9cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'senter',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEIs1EJK2ytH",
    "outputId": "6668a78d-a26b-484e-f860-192ebe0737d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'senter',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_sm').component_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5_kn-jYGz_G"
   },
   "source": [
    "You can view the accuracy parameters of various English language models [here](https://spacy.io/models/en) (Accuracy Evaluation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mntgw7BnIsTt"
   },
   "source": [
    "### Processing Text\n",
    "\n",
    "To process text, you need to pass it through the pipeline, which will return an instance of the [Doc](https://spacy.io/api/doc) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "8Rx_efr38z8j",
    "outputId": "150eecee-a336-462f-e159-afc6648c1d0c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The Leonardo da Vinci exhibition is held under the high patronage of French President Emmanuel Macron. The year 2019 marks the 500-year anniversary of the death of Leonardo da Vinci in France, of particular importance for the Louvre, which holds the largest collection in the world of da Vinci’s paintings, as well as 22 drawings.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The Leonardo da Vinci exhibition is held under the high patronage of French President Emmanuel Macron. \\\n",
    "The year 2019 marks the 500-year anniversary of the death of Leonardo da Vinci in France, of particular importance for the Louvre, \\\n",
    "which holds the largest collection in the world of da Vinci’s paintings, as well as 22 drawings.'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yP6Q2NyzKNpE",
    "outputId": "b4fbdceb-f57b-480d-a714-803d5a15c056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input text to nlp model and get SpaCy Document object\n",
    "doc = nlp(text)\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADk-aZotpzKb"
   },
   "source": [
    "Complete list of methods available in the `Doc` class: https://spacy.io/api/doc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbWs4VrdMQRW",
    "outputId": "99590797-030f-4c8c-b962-54dafa69e9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "__bytes__\n",
      "__class__\n",
      "__delattr__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__getitem__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__iter__\n",
      "__le__\n",
      "__len__\n",
      "__lt__\n",
      "__ne__\n",
      "__new__\n",
      "__pyx_vtable__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__setstate__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__unicode__\n",
      "_bulk_merge\n",
      "_context\n",
      "_get_array_attrs\n",
      "_realloc\n",
      "_vector\n",
      "_vector_norm\n",
      "cats\n",
      "char_span\n",
      "copy\n",
      "count_by\n",
      "doc\n",
      "ents\n",
      "extend_tensor\n",
      "from_array\n",
      "from_bytes\n",
      "from_dict\n",
      "from_disk\n",
      "from_docs\n",
      "from_json\n",
      "get_extension\n",
      "get_lca_matrix\n",
      "has_annotation\n",
      "has_extension\n",
      "has_unknown_spaces\n",
      "has_vector\n",
      "is_nered\n",
      "is_parsed\n",
      "is_sentenced\n",
      "is_tagged\n",
      "lang\n",
      "lang_\n",
      "mem\n",
      "noun_chunks\n",
      "noun_chunks_iterator\n",
      "remove_extension\n",
      "retokenize\n",
      "sentiment\n",
      "sents\n",
      "set_ents\n",
      "set_extension\n",
      "similarity\n",
      "spans\n",
      "tensor\n",
      "text\n",
      "text_with_ws\n",
      "to_array\n",
      "to_bytes\n",
      "to_dict\n",
      "to_disk\n",
      "to_json\n",
      "to_utf8_array\n",
      "user_data\n",
      "user_hooks\n",
      "user_span_hooks\n",
      "user_token_hooks\n",
      "vector\n",
      "vector_norm\n",
      "vocab\n"
     ]
    }
   ],
   "source": [
    "print(*dir(doc), sep ='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoqN8PU8M9uS"
   },
   "source": [
    "In this task, only the **sents** method will be used.\n",
    "\n",
    "(From Spacy documentation):  \n",
    "`sents`: **YIELDS** Sentences in the document.\n",
    "\n",
    "This is a generator, where each iterable element is a sentence (produced by the sentencizer).  \n",
    "Element type: `spacy.tokens.span.Span`. The methods of this class overlap with those of `spacy.tokens.doc.Doc`.\n",
    "\n",
    "\\* _The values yielded by the generator can be converted into a list._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lgzf2ZSGMTov",
    "outputId": "0fb40307-30ae-4334-cc2c-44b0a011ad4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x7a32ed8f34c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KYk4JYANnUC",
    "outputId": "1d8c0847-b786-4c93-9742-b6adbb87ae36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Leonardo da Vinci exhibition is held under the high patronage of French President Emmanuel Macron.\n",
      "The year 2019 marks the 500-year anniversary of the death of Leonardo da Vinci in France, of particular importance for the Louvre, which holds the largest collection in the world of da Vinci’s paintings, as well as 22 drawings.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UW46uM9R-hrY",
    "outputId": "613e71ff-ad1a-48ec-b2e2-4b49f2519346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Leonardo da Vinci exhibition is held under the high patronage of French President Emmanuel Macron.\n",
      "\n",
      "The year 2019 marks the 500-year anniversary of the death of Leonardo da Vinci in France, of particular importance for the Louvre, which holds the largest collection in the world of da Vinci’s paintings, as well as 22 drawings.\n"
     ]
    }
   ],
   "source": [
    "print(*list(doc.sents), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IF5QDrOKNsmJ",
    "outputId": "bd0f9d9c-343b-4c96-b31a-f324a492ae77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "  print(type(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhI40iAsN9uo"
   },
   "source": [
    "###Span and Token attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-mEFNRfOESY",
    "outputId": "bc9bb36d-c983-4460-db20-2eb92d9b385c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_fix_dep_copy',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'as_doc',\n",
       " 'char_span',\n",
       " 'conjuncts',\n",
       " 'doc',\n",
       " 'end',\n",
       " 'end_char',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ents',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_extension',\n",
       " 'has_vector',\n",
       " 'id',\n",
       " 'id_',\n",
       " 'kb_id',\n",
       " 'kb_id_',\n",
       " 'label',\n",
       " 'label_',\n",
       " 'lefts',\n",
       " 'lemma_',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'noun_chunks',\n",
       " 'orth_',\n",
       " 'remove_extension',\n",
       " 'rights',\n",
       " 'root',\n",
       " 'sent',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'start',\n",
       " 'start_char',\n",
       " 'subtree',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spacy.tokens.span.Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_2xiIaUNyvJ",
    "outputId": "55075632-f61e-4655-cfa8-c880268ed5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Leonardo da Vinci exhibition is held under the high patronage of French President Emmanuel Macron.\n",
      "Length: 17\n",
      "Noun chunks: {the high patronage, The Leonardo da Vinci exhibition, French President Emmanuel Macron}\n",
      "Ents: [Leonardo da Vinci, French, Emmanuel Macron]\n",
      "\n",
      "Sentence: The year 2019 marks the 500-year anniversary of the death of Leonardo da Vinci in France, of particular importance for the Louvre, which holds the largest collection in the world of da Vinci’s paintings, as well as 22 drawings.\n",
      "Length: 46\n",
      "Noun chunks: {Leonardo da Vinci, the largest collection, the world, the 500-year anniversary, da Vinci’s paintings, which, 22 drawings, The year, particular importance, the Louvre, the death, France}\n",
      "Ents: [The year 2019, 500-year, Leonardo da Vinci, France, da Vinci, 22]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main Token Attributes\n",
    "for sent in doc.sents:\n",
    "    print('Sentence:', sent)\n",
    "    print('Length:', sent.end - sent.start)  # Number of words (tokens) in the sentence (including punctuation)\n",
    "    print('Noun chunks:', set(sent.noun_chunks))  # Base noun phrases\n",
    "    print('Ents:', sent.ents)  # Named entities in the span\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-drtwXBlUm0i"
   },
   "source": [
    "Noun chunks - noun phrases.  \n",
    "Ents = named entity - a list of words/phrases in the sentence that have been recognized through [Named Entity Recognition](https://machinelearningknowledge.ai/named-entity-recognition-ner-in-spacy-library/?ysclid=m21epwuc6o95221647).  \n",
    "Let's examine the types of named entities in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86KOEVPBUmn2",
    "outputId": "57347ba5-0648-4646-f882-e899f5b99695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "named entities:\n",
      "(Leonardo da Vinci, ('PERSON', 'People, including fictional'))\n",
      "(French, ('NORP', 'Nationalities or religious or political groups'))\n",
      "(Emmanuel Macron, ('PERSON', 'People, including fictional'))\n",
      "\n",
      "named entities:\n",
      "(The year 2019, ('DATE', 'Absolute or relative dates or periods'))\n",
      "(500-year, ('DATE', 'Absolute or relative dates or periods'))\n",
      "(Leonardo da Vinci, ('PERSON', 'People, including fictional'))\n",
      "(France, ('GPE', 'Countries, cities, states'))\n",
      "(da Vinci, ('PERSON', 'People, including fictional'))\n",
      "(22, ('CARDINAL', 'Numerals that do not fall under another type'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "  entities = zip(sent.ents, [(s.label_, spacy.explain(str(s.label_))) for s in sent.ents])\n",
    "  print('named entities:',*entities, sep ='\\n', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgZOwAogZFCF"
   },
   "source": [
    "Full list of named entities:\n",
    "\n",
    "\"PERSON\": \"People, including fictional\",  \n",
    "\"NORP\": \"Nationalities or religious or political groups\",  \n",
    "\"FACILITY\": \"Buildings, airports, highways, bridges, etc.\",  \n",
    "\"FAC\": \"Buildings, airports, highways, bridges, etc.\",  \n",
    "\"ORG\": \"Companies, agencies, institutions, etc.\",  \n",
    "\"GPE\": \"Countries, cities, states\",  \n",
    "\"LOC\": \"Non-GPE locations, mountain ranges, bodies of water\",  \n",
    "\"PRODUCT\": \"Objects, vehicles, foods, etc. (not services)\",  \n",
    "\"EVENT\": \"Named hurricanes, battles, wars, sports events, etc.\",\n",
    "\"WORK_OF_ART\": \"Titles of books, songs, etc.\",\n",
    "\"LAW\": \"Named documents made into laws.\",  \n",
    "\"LANGUAGE\": \"Any named language\",  \n",
    "\"DATE\": \"Absolute or relative dates or periods\",  \n",
    "\"TIME\": \"Times smaller than a day\",  \n",
    "\"PERCENT\": 'Percentage, including \"%\"',  \n",
    "\"MONEY\": \"Monetary values, including unit\",  \n",
    "\"QUANTITY\": \"Measurements, as of weight or distance\",  \n",
    "\"ORDINAL\": '\"first\", \"second\", etc.',  \n",
    "\"CARDINAL\": \"Numerals that do not fall under another type\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k6ZEvzaBJdV"
   },
   "source": [
    "When iterating over a sentence, the objects returned are instances of the **Token** class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7r1Qn8w-UmiC",
    "outputId": "9d198748-f809-48ae-be1b-872b3b879b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "Leonardo\n",
      "da\n",
      "Vinci\n",
      "exhibition\n",
      "is\n",
      "held\n",
      "under\n",
      "the\n",
      "high\n",
      "patronage\n",
      "of\n",
      "French\n",
      "President\n",
      "Emmanuel\n",
      "Macron\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in list(doc.sents)[0]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSz_1d-iCDO1",
    "outputId": "e81342a2-87e7-4e3d-d4d1-e32832ab96a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n",
      "_\n",
      "__bytes__\n",
      "__class__\n",
      "__delattr__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__len__\n",
      "__lt__\n",
      "__ne__\n",
      "__new__\n",
      "__pyx_vtable__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__unicode__\n",
      "ancestors\n",
      "check_flag\n",
      "children\n",
      "cluster\n",
      "conjuncts\n",
      "dep\n",
      "dep_\n",
      "doc\n",
      "ent_id\n",
      "ent_id_\n",
      "ent_iob\n",
      "ent_iob_\n",
      "ent_kb_id\n",
      "ent_kb_id_\n",
      "ent_type\n",
      "ent_type_\n",
      "get_extension\n",
      "has_dep\n",
      "has_extension\n",
      "has_head\n",
      "has_morph\n",
      "has_vector\n",
      "head\n",
      "i\n",
      "idx\n",
      "iob_strings\n",
      "is_alpha\n",
      "is_ancestor\n",
      "is_ascii\n",
      "is_bracket\n",
      "is_currency\n",
      "is_digit\n",
      "is_left_punct\n",
      "is_lower\n",
      "is_oov\n",
      "is_punct\n",
      "is_quote\n",
      "is_right_punct\n",
      "is_sent_end\n",
      "is_sent_start\n",
      "is_space\n",
      "is_stop\n",
      "is_title\n",
      "is_upper\n",
      "lang\n",
      "lang_\n",
      "left_edge\n",
      "lefts\n",
      "lemma\n",
      "lemma_\n",
      "lex\n",
      "lex_id\n",
      "like_email\n",
      "like_num\n",
      "like_url\n",
      "lower\n",
      "lower_\n",
      "morph\n",
      "n_lefts\n",
      "n_rights\n",
      "nbor\n",
      "norm\n",
      "norm_\n",
      "orth\n",
      "orth_\n",
      "pos\n",
      "pos_\n",
      "prefix\n",
      "prefix_\n",
      "prob\n",
      "rank\n",
      "remove_extension\n",
      "right_edge\n",
      "rights\n",
      "sent\n",
      "sent_start\n",
      "sentiment\n",
      "set_extension\n",
      "set_morph\n",
      "shape\n",
      "shape_\n",
      "similarity\n",
      "subtree\n",
      "suffix\n",
      "suffix_\n",
      "tag\n",
      "tag_\n",
      "tensor\n",
      "text\n",
      "text_with_ws\n",
      "vector\n",
      "vector_norm\n",
      "vocab\n",
      "whitespace_\n"
     ]
    }
   ],
   "source": [
    "print(type(list(doc.sents)[0][0]))\n",
    "print(*dir(list(doc.sents)[0][0]), sep ='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtGjoMjESoLr"
   },
   "source": [
    "That is, using the attributes mentioned above, you can:\n",
    "\n",
    "- Obtain a list of words related to the token, including conjunctions (conjuncts), the text of the token (text), prefix, suffix, part-of-speech tag (POS tag), detailed part-of-speech tag (TAG), dependency tag (DEP), etc.\n",
    "\n",
    "Some `_Token` attributes are similar but have two variations: one with an underscore and one without. The variation with the underscore will return a string value, while the one without will return an integer ID value.  \n",
    "Let’s focus on the attributes that will be useful for completing the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMNaKyKfDjLD",
    "outputId": "d5504b02-e16b-4942-a266-326859e875be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        .i   .head     .norm_           .lemma_      .pos_     .tag_     .dep_     \n",
      "The          0    exhibitionthe              the          DET       DT        det       \n",
      "Leonardo     1    Vinci     leonardo         Leonardo     PROPN     NNP       compound  \n",
      "da           2    Vinci     da               da           PROPN     NNP       compound  \n",
      "Vinci        3    exhibitionvinci            Vinci        PROPN     NNP       compound  \n",
      "exhibition   4    held      exhibition       exhibition   NOUN      NN        nsubjpass \n",
      "is           5    held      is               be           AUX       VBZ       auxpass   \n",
      "held         6    held      held             hold         VERB      VBN       ROOT      \n",
      "under        7    held      under            under        ADP       IN        prep      \n",
      "the          8    patronage the              the          DET       DT        det       \n",
      "high         9    patronage high             high         ADJ       JJ        amod      \n",
      "patronage    10   under     patronage        patronage    NOUN      NN        pobj      \n",
      "of           11   patronage of               of           ADP       IN        prep      \n",
      "French       12   President french           french       ADJ       JJ        amod      \n",
      "President    13   Macron    president        President    PROPN     NNP       compound  \n",
      "Emmanuel     14   Macron    emmanuel         Emmanuel     PROPN     NNP       compound  \n",
      "Macron       15   of        macron           Macron       PROPN     NNP       pobj      \n",
      ".            16   held      .                .            PUNCT     .         punct     \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Token' : <13}{'.i' : <5}{'.head' : <10}{'.norm_' : <13}\\\n",
    "    {'.lemma_' : <13}{'.pos_' : <10}{'.tag_ ': <10}{'.dep_': <10}\")\n",
    "for token in list(doc.sents)[0]:\n",
    "    #print(*[token, token.text, token.lemma_, token.tag_, token.pos_, token.dep_], sep = '\\t')\n",
    "    print(f\"{str(token) : <13}{str(token.i) : <5}{str(token.head) : <10}{str(token.norm_) : <13}\\\n",
    "    {str(token.lemma_) : <13}{str(token.pos_) : <10}{str(token.tag_ ): <10}{str(token.dep_): <10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5zRel86IxfQ"
   },
   "source": [
    "You can view the complete list of tags [here](https://github.com/explosion/spaCy/blob/master/spacy/glossary.py).\n",
    "\n",
    "For convenience, the tag dictionary for English language models is presented below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "O-lRTL6EJOlW"
   },
   "outputs": [],
   "source": [
    "GLOSSARY = {\n",
    "    # POS tags\n",
    "    # Universal POS Tags\n",
    "    # http://universaldependencies.org/u/pos/\n",
    "    \"ADJ\": \"adjective\",\n",
    "    \"ADP\": \"adposition\",\n",
    "    \"ADV\": \"adverb\",\n",
    "    \"AUX\": \"auxiliary\",\n",
    "    \"CONJ\": \"conjunction\",\n",
    "    \"CCONJ\": \"coordinating conjunction\",\n",
    "    \"DET\": \"determiner\",\n",
    "    \"INTJ\": \"interjection\",\n",
    "    \"NOUN\": \"noun\",\n",
    "    \"NUM\": \"numeral\",\n",
    "    \"PART\": \"particle\",\n",
    "    \"PRON\": \"pronoun\",\n",
    "    \"PROPN\": \"proper noun\",\n",
    "    \"PUNCT\": \"punctuation\",\n",
    "    \"SCONJ\": \"subordinating conjunction\",\n",
    "    \"SYM\": \"symbol\",\n",
    "    \"VERB\": \"verb\",\n",
    "    \"X\": \"other\",\n",
    "    \"EOL\": \"end of line\",\n",
    "    \"SPACE\": \"space\",\n",
    "    # POS tags (English)\n",
    "    # OntoNotes 5 / Penn Treebank\n",
    "    # https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "    # https://universaldependencies.org/docs/en/pos/\n",
    "    \".\": \"punctuation mark, sentence closer\",\n",
    "    \",\": \"punctuation mark, comma\",\n",
    "    \"-LRB-\": \"left round bracket\",\n",
    "    \"-RRB-\": \"right round bracket\",\n",
    "    \"``\": \"opening quotation mark\",\n",
    "    '\"\"': \"closing quotation mark\",\n",
    "    \"''\": \"closing quotation mark\",\n",
    "    \":\": \"punctuation mark, colon or ellipsis\",\n",
    "    \"$\": \"symbol, currency\",\n",
    "    \"#\": \"symbol, number sign\",\n",
    "    \"AFX\": \"affix\",\n",
    "    \"CC\": \"conjunction, coordinating\",\n",
    "    \"CD\": \"cardinal number\",\n",
    "    \"DT\": \"determiner\",\n",
    "    \"EX\": \"existential there\",\n",
    "    \"FW\": \"foreign word\",\n",
    "    \"HYPH\": \"punctuation mark, hyphen\",\n",
    "    \"IN\": \"conjunction, subordinating or preposition\",\n",
    "    \"JJ\": \"adjective\",\n",
    "    \"JJR\": \"adjective, comparative\",\n",
    "    \"JJS\": \"adjective, superlative\",\n",
    "    \"LS\": \"list item marker\",\n",
    "    \"MD\": \"verb, modal auxiliary\",\n",
    "    \"NIL\": \"missing tag\",\n",
    "    \"NN\": \"noun, singular or mass\",\n",
    "    \"NNP\": \"noun, proper singular\",\n",
    "    \"NNPS\": \"noun, proper plural\",\n",
    "    \"NNS\": \"noun, plural\",\n",
    "    \"PDT\": \"predeterminer\",\n",
    "    \"POS\": \"possessive ending\",\n",
    "    \"PRP\": \"pronoun, personal\",\n",
    "    \"PRP$\": \"pronoun, possessive\",\n",
    "    \"RB\": \"adverb\",\n",
    "    \"RBR\": \"adverb, comparative\",\n",
    "    \"RBS\": \"adverb, superlative\",\n",
    "    \"RP\": \"adverb, particle\",\n",
    "    \"TO\": 'infinitival \"to\"',\n",
    "    \"UH\": \"interjection\",\n",
    "    \"VB\": \"verb, base form\",\n",
    "    \"VBD\": \"verb, past tense\",\n",
    "    \"VBG\": \"verb, gerund or present participle\",\n",
    "    \"VBN\": \"verb, past participle\",\n",
    "    \"VBP\": \"verb, non-3rd person singular present\",\n",
    "    \"VBZ\": \"verb, 3rd person singular present\",\n",
    "    \"WDT\": \"wh-determiner\",\n",
    "    \"WP\": \"wh-pronoun, personal\",\n",
    "    \"WP$\": \"wh-pronoun, possessive\",\n",
    "    \"WRB\": \"wh-adverb\",\n",
    "    \"SP\": \"space\",\n",
    "    \"ADD\": \"email\",\n",
    "    \"NFP\": \"superfluous punctuation\",\n",
    "    \"GW\": \"additional word in multi-word expression\",\n",
    "    \"XX\": \"unknown\",\n",
    "    \"BES\": 'auxiliary \"be\"',\n",
    "    \"HVS\": 'forms of \"have\"',\n",
    "    # Noun chunks\n",
    "    \"NP\": \"noun phrase\",\n",
    "    \"PP\": \"prepositional phrase\",\n",
    "    \"VP\": \"verb phrase\",\n",
    "    \"ADVP\": \"adverb phrase\",\n",
    "    \"ADJP\": \"adjective phrase\",\n",
    "    \"SBAR\": \"subordinating conjunction\",\n",
    "    \"PRT\": \"particle\",\n",
    "    \"PNP\": \"prepositional noun phrase\",\n",
    "    # Dependency Labels (English)\n",
    "    # ClearNLP / Universal Dependencies\n",
    "    # https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "    # https://universaldependencies.org/docs/en/dep/\n",
    "     \"acl\": \"clausal modifier of noun (adjectival clause)\",\n",
    "    \"acomp\": \"adjectival complement\",\n",
    "    \"advcl\": \"adverbial clause modifier\",\n",
    "    \"advmod\": \"adverbial modifier\",\n",
    "    \"agent\": \"agent\",\n",
    "    \"amod\": \"adjectival modifier\",\n",
    "    \"appos\": \"appositional modifier\",\n",
    "    \"attr\": \"attribute\",\n",
    "    \"aux\": \"auxiliary\",\n",
    "    \"auxpass\": \"auxiliary (passive)\",\n",
    "    \"case\": \"case marking\",\n",
    "    \"cc\": \"coordinating conjunction\",\n",
    "    \"ccomp\": \"clausal complement\",\n",
    "    \"clf\": \"classifier\",\n",
    "    \"complm\": \"complementizer\",\n",
    "    \"compound\": \"compound\",\n",
    "    \"conj\": \"conjunct\",\n",
    "    \"cop\": \"copula\",\n",
    "    \"csubj\": \"clausal subject\",\n",
    "    \"csubjpass\": \"clausal subject (passive)\",\n",
    "    \"dative\": \"dative\",\n",
    "    \"dep\": \"unclassified dependent\",\n",
    "    \"det\": \"determiner\",\n",
    "    \"discourse\": \"discourse element\",\n",
    "    \"dislocated\": \"dislocated elements\",\n",
    "    \"dobj\": \"direct object\",\n",
    "    \"expl\": \"expletive\",\n",
    "    \"fixed\": \"fixed multiword expression\",\n",
    "    \"flat\": \"flat multiword expression\",\n",
    "    \"goeswith\": \"goes with\",\n",
    "    \"hmod\": \"modifier in hyphenation\",\n",
    "    \"hyph\": \"hyphen\",\n",
    "    \"infmod\": \"infinitival modifier\",\n",
    "    \"intj\": \"interjection\",\n",
    "    \"iobj\": \"indirect object\",\n",
    "    \"list\": \"list\",\n",
    "    \"mark\": \"marker\",\n",
    "    \"meta\": \"meta modifier\",\n",
    "    \"neg\": \"negation modifier\",\n",
    "    \"nmod\": \"modifier of nominal\",\n",
    "    \"nn\": \"noun compound modifier\",\n",
    "    \"npadvmod\": \"noun phrase as adverbial modifier\",\n",
    "    \"nsubj\": \"nominal subject\",\n",
    "    \"nsubjpass\": \"nominal subject (passive)\",\n",
    "    \"nounmod\": \"modifier of nominal\",\n",
    "    \"npmod\": \"noun phrase as adverbial modifier\",\n",
    "    \"num\": \"number modifier\",\n",
    "    \"number\": \"number compound modifier\",\n",
    "    \"nummod\": \"numeric modifier\",\n",
    "    \"oprd\": \"object predicate\",\n",
    "    \"obj\": \"object\",\n",
    "    \"obl\": \"oblique nominal\",\n",
    "    \"orphan\": \"orphan\",\n",
    "    \"parataxis\": \"parataxis\",\n",
    "    \"partmod\": \"participal modifier\",\n",
    "    \"pcomp\": \"complement of preposition\",\n",
    "    \"pobj\": \"object of preposition\",\n",
    "    \"poss\": \"possession modifier\",\n",
    "    \"possessive\": \"possessive modifier\",\n",
    "    \"preconj\": \"pre-correlative conjunction\",\n",
    "    \"prep\": \"prepositional modifier\",\n",
    "    \"prt\": \"particle\",\n",
    "    \"punct\": \"punctuation\",\n",
    "    \"quantmod\": \"modifier of quantifier\",\n",
    "    \"rcmod\": \"relative clause modifier\",\n",
    "    \"relcl\": \"relative clause modifier\",\n",
    "    \"reparandum\": \"overridden disfluency\",\n",
    "    \"root\": \"root\",\n",
    "    \"vocative\": \"vocative\",\n",
    "    \"xcomp\": \"open clausal complement\",\n",
    "    # Named Entity Recognition\n",
    "    # OntoNotes 5\n",
    "    # https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf\n",
    "    \"PERSON\": \"People, including fictional\",\n",
    "    \"NORP\": \"Nationalities or religious or political groups\",\n",
    "    \"FACILITY\": \"Buildings, airports, highways, bridges, etc.\",\n",
    "    \"FAC\": \"Buildings, airports, highways, bridges, etc.\",\n",
    "    \"ORG\": \"Companies, agencies, institutions, etc.\",\n",
    "    \"GPE\": \"Countries, cities, states\",\n",
    "    \"LOC\": \"Non-GPE locations, mountain ranges, bodies of water\",\n",
    "    \"PRODUCT\": \"Objects, vehicles, foods, etc. (not services)\",\n",
    "    \"EVENT\": \"Named hurricanes, battles, wars, sports events, etc.\",\n",
    "    \"WORK_OF_ART\": \"Titles of books, songs, etc.\",\n",
    "    \"LAW\": \"Named documents made into laws.\",\n",
    "    \"LANGUAGE\": \"Any named language\",\n",
    "    \"DATE\": \"Absolute or relative dates or periods\",\n",
    "    \"TIME\": \"Times smaller than a day\",\n",
    "    \"PERCENT\": 'Percentage, including \"%\"',\n",
    "    \"MONEY\": \"Monetary values, including unit\",\n",
    "    \"QUANTITY\": \"Measurements, as of weight or distance\",\n",
    "    \"ORDINAL\": '\"first\", \"second\", etc.',\n",
    "    \"CARDINAL\": \"Numerals that do not fall under another type\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "hDUDnETPJ0bo",
    "outputId": "6fc7da2d-3d33-4591-d105-d7bb86484092"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOSSARY[\"nsubj\"] # Examples of sentences: https://universaldependencies.org/docs/en/dep/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoHvrahtMfj1"
   },
   "source": [
    "### Token.morph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eb0fZQtaMenc",
    "outputId": "18cf96ab-7935-4b28-8ebd-7ac4a3091a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token       .morph      \n",
      "The         Definite=Def|PronType=Art\n",
      "Leonardo    Number=Sing \n",
      "da          Number=Sing \n",
      "Vinci       Number=Sing \n",
      "exhibition  Number=Sing \n",
      "is          Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "held        Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "under                   \n",
      "the         Definite=Def|PronType=Art\n",
      "high        Degree=Pos  \n",
      "patronage   Number=Sing \n",
      "of                      \n",
      "French      Degree=Pos  \n",
      "President   Number=Sing \n",
      "Emmanuel    Number=Sing \n",
      "Macron      Number=Sing \n",
      ".           PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Token' : <12}{'.morph' : <12}\")\n",
    "for token in list(doc.sents)[0]:\n",
    "    print(f\"{str(token) : <12}{str(token.morph) : <12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP3eG9uevoCk"
   },
   "source": [
    "### Text pre-processing for French data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNRrxu_7v66v"
   },
   "source": [
    "For stemming you can use SnowballStemmer: https://www.nltk.org/api/nltk.stem.SnowballStemmer.html?highlight=stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1aDyKYxvnD4",
    "outputId": "bb6f92c7-3988-42e7-dd59-c42ca0b90801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "SpaCy est une bibliothèque NLP incroyable.\n",
      "Elle aide au traitement de texte !\n",
      "\n",
      "Tokens: ['SpaCy', 'est', 'une', 'bibliothèque', 'NLP', 'incroyable', '.', 'Elle', 'aide', 'au', 'traitement', 'de', 'texte', '!']\n",
      "Lowercase Tokens: ['spacy', 'est', 'une', 'bibliothèque', 'nlp', 'incroyable', '.', 'elle', 'aide', 'au', 'traitement', 'de', 'texte', '!']\n",
      "Stop Words: ['est', 'une', 'Elle', 'au', 'de']\n",
      "Lemmatized Tokens: ['spacy', 'être', 'un', 'bibliothèque', 'NLP', 'incroyable', '.', 'lui', 'aide', 'au', 'traitement', 'de', 'texte', '!']\n",
      "Stemmed Tokens: ['spacy', 'est', 'une', 'bibliothequ', 'nlp', 'incroi', '.', 'elle', 'aid', 'au', 'trait', 'de', 'text', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Load the French SpaCy model\n",
    "nlp_french = spacy.load('fr_core_news_sm')\n",
    "\n",
    "# Sample French text\n",
    "text = \"SpaCy est une bibliothèque NLP incroyable. Elle aide au traitement de texte !\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp_french(text)\n",
    "\n",
    "# 1 Sentence segmentation\n",
    "sentences = list(doc.sents)\n",
    "print(\"Sentences:\")\n",
    "for sentence in sentences:\n",
    "    print(sentence.text)\n",
    "\n",
    "# 2 Tokenization\n",
    "tokens = [token.text for token in doc]\n",
    "print(\"\\nTokens:\", tokens)\n",
    "\n",
    "# 3 Lowercasing\n",
    "lowercase_tokens = [token.text.lower() for token in doc]\n",
    "print(\"Lowercase Tokens:\", lowercase_tokens)\n",
    "\n",
    "# 4 Check for stop words\n",
    "stop_words = [token.text for token in doc if token.is_stop]\n",
    "print(\"Stop Words:\", stop_words)\n",
    "\n",
    "# 5 Lemmatization\n",
    "lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "\n",
    "# 6 Stemming\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "stemmed_tokens = [stemmer.stem(token.text) for token in doc]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2vZdkgXLiBz"
   },
   "source": [
    "### Matcher patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fqmGa5UPB35"
   },
   "source": [
    "To check if a sentence matches a specified pattern, you can use one of three SpaCy classes:\n",
    "\n",
    "1) **Matcher** - You can use `pos` and `tag` tags, as well as token attributes, to construct the pattern.\n",
    "\n",
    "2) **DependencyMatcher** - You can use syntactic dependencies (e.g., be a sibling of) to create a pattern for the syntactic tree.\n",
    "\n",
    "3) **PhraseMatcher** - Matches specific phrases and word combinations.\n",
    "\n",
    "### Matcher class\n",
    "First, you need to create a `pattern`, then instantiate `matcher = Matcher(vocab=nlp.vocab)` and pass the `pattern` to the matcher using `matcher.add(\"pattern name\", patterns=[pattern])`.\n",
    "\n",
    "You can view the results of text matches for each `doc` with `matcher(doc, as_spans=True)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlYnSZKWT4zM"
   },
   "source": [
    "Creating a pattern is the primary task.  \n",
    "In the case of **Matcher**, the `pattern` must be a list of dictionaries. Each dictionary corresponds to one token, with the keys representing the token attributes. You can also use the key `_OP`. Possible values for `_OP` are:\n",
    "\n",
    "1. `!`  Negate the pattern by requiring it to match exactly 0 times.\n",
    "2. `?`  Make the pattern optional by allowing it to match 0 or 1 times.\n",
    "3. `+`  Require the pattern to match 1 or more times.\n",
    "4. `*`  Allow the pattern to match 0 or more times.\n",
    "\n",
    "Other available keys and their descriptions can be found at [Pattern format](https://spacy.io/api/matcher).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fab9sV6BLhNl",
    "outputId": "6a3bda44-5b8b-437e-9c69-e2e4dac1f071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.matcher.matcher.Matcher at 0x7a32e50072e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = Matcher(vocab=nlp.vocab)\n",
    "matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "KymOXhGZQbZy"
   },
   "outputs": [],
   "source": [
    "noun_phrase_verb = [{'POS': 'NOUN', 'OP': '+'}, {'POS': 'VERB', 'OP': '+'}]\n",
    "matcher.add(\"noun_phrase+verb\", patterns=[noun_phrase_verb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZvQMZfCdcyt",
    "outputId": "a529b429-6543-4375-c3e2-31b0a6d2528e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-09 05:37:02--  https://drive.google.com/uc?export=download&id=1cK8FATtEGxC2kWv3FCthdrZZWM01c2sw\n",
      "Resolving drive.google.com (drive.google.com)... 64.233.181.102, 64.233.181.100, 64.233.181.101, ...\n",
      "Connecting to drive.google.com (drive.google.com)|64.233.181.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1cK8FATtEGxC2kWv3FCthdrZZWM01c2sw&export=download [following]\n",
      "--2024-10-09 05:37:02--  https://drive.usercontent.google.com/download?id=1cK8FATtEGxC2kWv3FCthdrZZWM01c2sw&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.214.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2146822 (2.0M) [application/octet-stream]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   2.05M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-10-09 05:37:05 (154 MB/s) - ‘input.txt’ saved [2146822/2146822]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load text corpus\n",
    "!wget -O input.txt 'https://drive.google.com/uc?export=download&id=1cK8FATtEGxC2kWv3FCthdrZZWM01c2sw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Jne0ygvfMrc",
    "outputId": "ea1b6df0-1d76-456e-bd85-76653ea95bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun_phrase+verb \t complainant wants\n",
      "noun_phrase+verb \t woman named\n",
      "noun_phrase+verb \t judge acquit\n",
      "noun_phrase+verb \t prosecutor revealed\n",
      "noun_phrase+verb \t complainant wants\n",
      "noun_phrase+verb \t woman named\n",
      "noun_phrase+verb \t judge acquit\n",
      "noun_phrase+verb \t prosecutor revealed\n"
     ]
    }
   ],
   "source": [
    "with open('./' + 'input.txt', encoding='utf-8') as file:\n",
    "    for text in file.readlines()[:2]:\n",
    "        doc = nlp(text)\n",
    "        for sent in list(doc.sents)[:2]:\n",
    "            d = nlp(str(sent))\n",
    "            # as_spans=True - for text representation of results\n",
    "            results = matcher(doc, as_spans=True)\n",
    "            for result in results:\n",
    "                print(nlp.vocab[result.label].text, '\\t', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lg5ecWVnhzuc"
   },
   "source": [
    "The found matches correspond to the pattern.  \n",
    "However, for instance, when searching for a noun and a verb with words of other parts of speech in between, the pattern may become overly complicated. To tackle such tasks, or, for example, the task of finding the subject and predicate, it is necessary to use syntactic trees, i.e., to look for a noun whose parent is the root (in the case of a simple sentence). For these types of tasks, you should use **DependencyMatcher**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh6jxghItlWv"
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write code to use the matcher to extract the following phrases from the text:\n",
    "\n",
    "- **Pattern 1:** Match any noun followed by a verb (e.g., \"cat sleeps\").\n",
    "- **Pattern 2:** Match the phrase \"not [adjective]\" (e.g., \"not happy\").\n",
    "- **Pattern 3:** Match a proper noun followed by a verb (e.g., \"Alice runs\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pxt8lkhnth4K"
   },
   "outputs": [],
   "source": [
    "# Your code\n",
    "# matcher = Matcher(vocab=nlp.vocab)\n",
    "# pattern = []\n",
    "# matcher.add(\"pattern\", patterns=[pattern])\n",
    "# with open('./' + 'input.txt', encoding='utf-8') as file:\n",
    "#     for text in file.readlines()[:2]:\n",
    "#         doc = nlp(text)\n",
    "#         for sent in list(doc.sents)[:2]:\n",
    "#             d = nlp(str(sent))\n",
    "#             # as_spans=True - for text representation of results\n",
    "#             results = matcher(doc, as_spans=True)\n",
    "#             for result in results:\n",
    "#                 print(nlp.vocab[result.label].text, '\\t', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1dkzFwNH9QY"
   },
   "source": [
    "### DependencyMatcher class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbutumZlmxKk"
   },
   "source": [
    "The principle of creating a **DependencyMatcher** is similar to that of the **Matcher**, but it differs significantly in pattern construction.\n",
    "\n",
    "A description of the pattern keys can be found in the documentation: [Pattern format](https://spacy.io/api/dependencymatcher).\n",
    "\n",
    "### Pattern for **DependencyMatcher**\n",
    "\n",
    "The pattern must be a list, where each element specifies the match for a token and is a dictionary.\n",
    "\n",
    "___\n",
    "**Dictionary for the First Element**\n",
    "___\n",
    "The dictionary for the first element must include the following keys:\n",
    "- `RIGHT_ID`: the name of the token (can be any name);\n",
    "- `RIGHT_ATTRS`: a dictionary of the token's attributes.\n",
    "\n",
    "The attributes can include any properties of the token.\n",
    "\n",
    "___\n",
    "**Dictionaries for the Other Elements**\n",
    "___\n",
    "Dictionaries for matching other tokens must include the following four keys: `LEFT_ID`, `REL_OP`, `RIGHT_ID`, and `RIGHT_ATTRS`.\n",
    "\n",
    "- `LEFT_ID`: the name of the left-dependent vertex;\n",
    "- `REL_OP`: the operand that describes the dependency of the token from this dictionary on the vertex `LEFT_ID`;\n",
    "- `RIGHT_ID`: the name of the token (also specified at the creator's discretion);\n",
    "- `RIGHT_ATTRS`: a dictionary where the keys are the attributes of the token.\n",
    "\n",
    "Possible `REL_OP` values can be found in the [Pattern format](https://spacy.io/api/dependencymatcher):\n",
    "\n",
    "- **A < B:** A is the immediate dependent of B.\n",
    "- **A > B:** A is the immediate head of B.\n",
    "- **A << B:** A is the dependent in a chain to B following dep → head paths.\n",
    "- **A >> B:** A is the head in a chain to B following head → dep paths.\n",
    "- **A . B:** A immediately precedes B, i.e., A.i == B.i - 1, and both are within the same dependency tree.\n",
    "- **A .* B:** A precedes B, i.e., A.i < B.i, and both are within the same dependency tree (not in Semgrex).\n",
    "- **A ; B:** A immediately follows B, i.e., A.i == B.i + 1, and both are within the same dependency tree (not in Semgrex).\n",
    "- **A ;* B:** A follows B, i.e., A.i > B.i, and both are within the same dependency tree (not in Semgrex).\n",
    "- **A \\$+ B:** B is a right immediate sibling of A, i.e., A and B have the same parent and A.i == B.i - 1.\n",
    "- **A \\$- B:** B is a left immediate sibling of A, i.e., A and B have the same parent and A.i == B.i + 1.\n",
    "- **A \\$++ B:** B is a right sibling of A, i.e., A and B have the same parent and A.i < B.i.\n",
    "- **A \\$-- B:** B is a left sibling of A, i.e., A and B have the same parent and A.i > B.i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3buf6gnYhY4"
   },
   "source": [
    "To choose an `REL_OP`, it is advisable to first look at the values of the attributes `token.head` and `token.root` in a specific sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "IeZAKFAvmw30"
   },
   "outputs": [],
   "source": [
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "AB3iuw1XuY4-"
   },
   "outputs": [],
   "source": [
    "with open('./' + 'input.txt', encoding='utf-8') as file:\n",
    "  text = file.readlines()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "szV2BAY6tvFv"
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z0QwF-QtneH",
    "outputId": "c06896a7-d74c-45bd-b069-03fd561cf0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        .i   .head     .norm_       .pos_     .tag_     .dep_     \n",
      "﻿When        0    have      ﻿when        ADV       RB        advmod    \n",
      "a            1    few       a            DET       DT        quantmod  \n",
      "few          2    people    few          ADJ       JJ        nummod    \n",
      "completely   3    different completely   ADV       RB        advmod    \n",
      "different    4    people    different    ADJ       JJ        amod      \n",
      "people       5    have      people       NOUN      NNS       nsubj     \n",
      "have         6    have      have         VERB      VBP       ROOT      \n",
      "to           7    share     to           PART      TO        aux       \n",
      "share        8    have      share        VERB      VB        xcomp     \n",
      "a            9    number    a            DET       DT        det       \n",
      "flat         10   number    flat         ADJ       JJ        amod      \n",
      ",            11   number    ,            PUNCT     ,         punct     \n",
      "very         12   often     very         ADV       RB        advmod    \n",
      "often        13   number    often        ADV       RB        advmod    \n",
      "a            14   number    a            DET       DT        det       \n",
      "number       15   share     number       NOUN      NN        dobj      \n",
      "of           16   number    of           ADP       IN        prep      \n",
      "difficulties 17   of        difficulties NOUN      NNS       pobj      \n",
      "emerge       18   have      emerge       VERB      VBP       advcl     \n",
      ".            19   have      .            PUNCT     .         punct     \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Token' : <13}{'.i' : <5}{'.head' : <10}{'.norm_' : <13}\\\n",
    "{'.pos_' : <10}{'.tag_ ': <10}{'.dep_': <10}\")\n",
    "for token in list(doc.sents)[0]:\n",
    "    #print(*[token, token.text, token.lemma_, token.tag_, token.pos_, token.dep_], sep = '\\t')\n",
    "    print(f\"{str(token) : <13}{str(token.i) : <5}{str(token.head) : <10}{str(token.norm_) : <13}{str(token.pos_) : <10}{str(token.tag_ ): <10}{str(token.dep_): <10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAWWUUodvxNf"
   },
   "source": [
    "Let's try to create a pattern to search for: **number(s) of + noun**.\n",
    "\n",
    "In the above sentence, **number** is the head for **of**, and **of** is the head for **difficulties**.\n",
    "\n",
    "The operand corresponding to \"be a head of\" is: **A < B**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Ivy6G2tX2EKY"
   },
   "outputs": [],
   "source": [
    "dep_matcher = DependencyMatcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "llTQjE_R2MzO"
   },
   "outputs": [],
   "source": [
    "dep_pattern = [{'RIGHT_ID': 'number', 'RIGHT_ATTRS': {'NORM': 'number'}},\n",
    "               {'LEFT_ID': 'number', 'REL_OP': '>', 'RIGHT_ID': 'prep', 'RIGHT_ATTRS': {'NORM': 'of'}},\n",
    "                {'LEFT_ID': 'prep', 'REL_OP': '>', 'RIGHT_ID': 'noun', 'RIGHT_ATTRS': {'TAG':{'IN': ['NNS', 'NN']}, 'DEP': 'pobj'}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8ACxgSXv5vk",
    "outputId": "6a8d9ccf-4f47-45de-fb90-3c381880e0de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8480868639249277778, [15, 16, 17])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_matcher.add('number_of_pattern', patterns=[dep_pattern])\n",
    "dep_matches = dep_matcher(doc)\n",
    "dep_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RA9Lkguo4xt2",
    "outputId": "6ec6b238-702c-4058-a720-505c8693eafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_pattern \t number ... of difficulties\n"
     ]
    }
   ],
   "source": [
    "for match in dep_matches:\n",
    "    pattern_name = match[0]\n",
    "    matches = match[1]\n",
    "    print(nlp.vocab[pattern_name].text, '\\t', doc[ matches[0]], '...', doc[matches[1]], doc[matches[2]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
